---
layout:     post
title: Scrapy框架架构流程介绍
subtitle: 爬虫框架
date:       2018-01-20
author:     Los-GTI
header-img: img/post-bg-swift.jpg
catalog: true
tags:
    - Scrapy
---

#### 1.Scrapy框架介绍
- Scrapy是用纯Python实现的一个为了爬取网站数据、提取结构性数据而编写的应用框架，用途十分广泛。
- 用户只需要定制开发几个模块就可以轻松实现一个爬虫，用来抓取网页内容以及各种图片，非常方便。
- Scapy使用了Twisted（其主要对手是Tornado）异步网络框架来处理网络通讯，可以加快我们的加载速度，不用自己去实现异步框架，并且包含了各种中间件接口，可以灵活的完成各种需求。
#### 2.Scrapy架构图及详解（绿线是数据流向）

![](https://raw.githubusercontent.com/Los-GTI/Los-GTI.github.io/master/img/Scrapy架构1.png)

- Scrapy Engine（引擎）：复制Spider、ItemPipeline、Downloader、Scheduler中间的通讯，信号、数据传递等。
- Scheduler（调度器）：它负责接受引擎发送过来的Request请求，并按照一定的方式进行整理排列，入队，当引擎需要时还给引擎。
- Downloader（下载器）：负责下载Scrapy Engine（引擎）发送的所有Requests请求，并将其获取到的Response交还给Scrapy Engine（引擎），由引擎交给Spider来处理。
- Spider（爬虫）：它负责处理所有的Responses，从中分析提取数据，获取Item字段需要的数据，并将需要跟进的URL提交给引擎，再次进入Scheduler（调度器）。
- Item Pipeline（管道）：它负责处理Spider中获取到的Item，并进行后期处理（详细分析、过滤、存储等）的地方。
- Downloader Middlewares（下载中间件）：你可以当作是一个可以自定义扩展下载功能的组件。
- Spider Middlewares（Spider 中间件）：可以理解为是一个可以自定义扩展和操作引擎和Spider中间通信的功能组件（比如进入Spider的Responses和从Spider出去的Requests）

#### 3.Scrapy的工作流程

- 首先在Spiders里面定义一开始要爬取的URL地址，把请求构建好然后交给引擎
- 引擎会把请求交给调度器，调度器把请求入队列，调度器按照一定的方式将请求整理排列，然后请求根据排列顺序出队列交给下载器去下载
- 下载器下载好之后返回响应文件，从响应文件中提取相关的URL地址或者Item数据，如果是URL地址就在Spiders中再将URL地址构建成请求再给调度器，如果是Item数据就交给管道去处理
- 调度器将所有请求入队列，中间经过去重操作，相同的URL就不会入队列了，然后请求再出队列交给下载器去下载，下载器下载完成之后再返回响应文件，这样一直循环只有当调度器中不存在任何request了程序才会停止（也就是说，对于下载失败的URLScrapy也会重新下载）。
- 直到拿到网页的返回文件了，我们就可以提取出来标题等内容，取到数据之后交给管道处理，这时候管道才开始工作

> 摁钉 author by Los-GTI


