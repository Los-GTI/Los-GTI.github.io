---
layout:     post
title:      混口饭吃专题之Java面试基础1.0
subtitle:   Java面试基础1.0
date:       2018-04-04
author:     Los-GTI
header-img: img/ms4.jpg
catalog: true
tags:
    - 混口饭吃
---

[TOC]
### 1. java基础
##### 1.1 String、StringBuilder、StringBuffer的区别是什么？String为什么不可变？
（1）String是字符串常量，StringBuffer和StringBuilder都是字符串变量，后两者的字符内容可变，而前者创建后内容不可变。（2）String不可变是因为在JDK中String类被声明为一个final类，用final修饰的类不能被继承，不能拥有自己的子类。
（3）StringBuffer是线程安全的，而StringBuilder是非线程安全的。Ps：线程安全会带来额外的开销，所以StringBuilder会比StringBuffer的效率更高，如果对系统中的线程是否安全很掌握可以使用StringBuffer，在线程不安全处加上关键字Synchronsized。
##### 1.2 HashTable、HashMap、TreeMap区别？
主要的区别有线程安全性、同步（synchronization）以及速度。
1.HashTable线程同步，HashMap非线程同步。这意味着Hashtable是线程安全的，多个线程可以共享HashTable，而如果没有正确的同步的话，多个线程是不能共享HashMap的。Java5提供了ConcurrentHashMap，它是HashTable的替代，比HashTable的扩展性更好。Ps：线程同步的意思是当有一个线程在对内存进行操作时其它线程都不可以对这个内存再进行操作，直到这个线程完成操作后其它线程才可以对这个内存执行操作（java通过在方法前加synchronized）。
2.HashTable不允许<key,value>有空值，HashMap允许<key,value>有空值；
3.HashMap的迭代器Iterator是fail-first迭代器，而HashTable的enumerator迭代器不是fail-first的，所以当有其它线程改变了HashMap的结构（增加或者移除元素），将会抛出ConcurrentModificationException，但迭代器本身的remove()方法移除元素则不会抛出ConcurrentModificationException异常。
4.由于Hashtable是线程安全的也是synchronized，所以在单线程环境下它比HashMap要慢。如果你不需要同步，只需要单一线程，那么使用HashMap性能要好过Hashtable。
4.TreeMap能够把它保存的记录根据键排序，默认是按升序排序。

###### 1.2.1 hashMap是怎么实现的？
HashMap 底层就是一个数组，数组中的每一项又是一个链表（jdk1.8有可能为红黑树）。
当新建一个 HashMap 的时候，就会初始化一个数组。
根据对象的 hashCode 方法在数组中定位元素，再根据 equals 方法在链表中定位节点。
但是HashTable线程安全的策略实现代价却太大了，简单粗暴，get/put所有相关操作都是synchronized的，这相当于给整个哈希表加了一把大锁，多线程访问时候，只要有一个线程访问或操作该对象，那其他线程只能阻塞，相当于将所有的操作串行化，在竞争激烈的并发场景中性能就会非常差。
###### 1.2.2 ConcurrentHashMap
HashTable性能差主要是由于所有操作需要竞争同一把锁，而如果容器中有多把锁，每一把锁锁一段数据，这样在多线程访问时不同段的数据时，就不会存在锁竞争了，这样便可以有效地提高并发效率。这就是ConcurrentHashMap所采用的"分段锁"思想。
ConcurrentHashMap采用了非常精妙的"分段锁"策略，ConcurrentHashMap的主干是个Segment数组。
Segment继承了ReentrantLock，所以它就是一种可重入锁（ReentrantLock)。在ConcurrentHashMap，一个Segment就是一个子哈希表，Segment里维护了一个HashEntry数组，并发环境下，对于不同Segment的数据进行操作是不用考虑锁竞争的。（就按默认的ConcurrentLeve为16来讲，理论上就允许16个线程并发执行，有木有很酷）
所以，对于同一个Segment的操作才需考虑线程同步，不同的Segment则无需考虑。

###### 1.2.3 HashMap 和 ConcurrentHashMap区别，  ConcurrentHashMap  线程安全吗，  ConcurrentHashMap如何保证 线程安全？

是否线程安全：ConcurrentMap 采用了分段锁的机制，在进行多线程写操作时只需要为写入位置所在的 segment  加锁，以确保同一时刻只有一个线程修改这个segment的数据

##### 1.3 面向对象的特性
封装：把客观事物封装成抽象的类，并且类可以把自己的属性和方法只让可信的类或者对象操作，对不可信的进行信息隐藏；
继承：父类可以派生出子类，子类可以使用父类的所有属性和方法，并在无需重新编写原来的类的基础上对这些属性和方法进行扩展；
多态：是指一个类实例的相同方法在不同情形有不同表现形式。多态机制使具有不同内部结构的对象可以共享相同的外部接口。这意味着，虽然针对不同对象的具体操作不同，但通过一个公共的类，它们（那些操作）可以通过相同的方式予以调用。
##### 1.4 jvm的类加载机制
定义：虚拟机把描述类的数据从Class文件加载到内存，并对数据进行校验、转换解析和初始化，最终形成可以被虚拟机直接使用的java类型，这就是虚拟机的加载机制。
生命周期：类从被加载到虚拟机内存开始，到卸载出内存为止，它的整个生命周期包括：加载、验证、准备、解析、初始化、使用和卸载7个阶段，其中验证、准备、解析3个部分统称为连接；加载、验证、准备初始化、卸载这5个阶段的顺序是确定的，类的加载过程必须按照这种顺序按部就班的开始，而解析阶段不一定；
类加载器：启动类加载器、扩展类加载器、应用程序类加载器

##### 1.5 JVM如何加载一个类的过程，双亲委派模型中有哪些方法？ 

类加载过程：加载、验证、准备、解析、初始化（LVPRI）

- 加载（Loading）：根据类全限定名加载二进制字节流，将二进制字节流的静态存储结构转化为动态数据结构，在内存中（Java堆）初始化一个 java.lang.Class 对象，作为方法区访问该类的入口

- 验证（Verification）：验证字节流是否符合JVM规范

- 准备（Preparation）：为类的static变量分配内存，并赋初值（final变量赋真实值，非final变量赋0）

- 解析（Resolution）：把符号引用替换为直接引用

- 初始化（Initialization）：进一步初始化（父类、构造函数）


双亲委派模型：

启动类加载器（Bootstrap）、扩展类加载器（Extend）、应用程序类加载器（Application）、自定义类加载器（User）

组合方式实现，而非继承。

首先将加载任务委托给父类加载器，依次递归，如果父类加载器可以完成类加载任务，就成功返回；只有父类加载器无法完成此加载任务时，才自己去加载。

```java
protected synchronized Class<?> loadClass(String name, boolean resolve)   throws ClassNotFoundException{  
    // First, check if the class has already been loaded  
    Class c = findLoadedClass(name);  
    if (c == null) {  
        try {  
            if (parent != null) {  
                c = parent.loadClass(name, false);  
            } else {  
                c = findBootstrapClassOrNull(name);  
            }  
        } catch (ClassNotFoundException e) {  
            // ClassNotFoundException thrown if class not found  
            // from the non-null parent class loader  
        }  
        if (c == null) {  
            // If still not found, then invoke findClass in order  
            // to find the class.  
            c = findClass(name);  
        }  
    }  
    if (resolve) {  
        resolveClass(c);  
    }  
    return c;  
}  
```
##### 1.6 Object类有哪些方法
- toString()：返回该对象的字符串表示

- hashCode()：返回对象的Hash值

  ```
   // String 的 hashCode, hash = s[0]*31^(n-1) + s[1]*31^(n-2) + ... + s[n-1]
  public int hashCode() {
      int h = hash;
      if (h == 0 && value.length > 0) {
          char val[] = value;
          for (int i = 0; i < value.length; i++) {
              h = 31 * h + val[i];
          }
          hash = h;
      }
      return h;
  }
  ```


- wait():在其他线程调用此对象的 notify() 方法或 notifyAll() 方法前，导致当前线程等待。

- notify():唤醒在此对象监视器上等待的单个线程。

- notifyAll():唤醒在此对象监视器上等待的所有线程。

- clone()：创建并返回当前对象的一份拷贝。

  一般情况下，对于任何对象 x，表达式 x.clone() **!=** x 为true，x.clone().getClass() == x.getClass() 也为true。

  由于Object本身没有实现Cloneable接口，所以不重写clone方法并且进行调用的话会发生CloneNotSupportedException异常。

- equals()：比较两个对象是否相等。Object类的默认实现，即比较2个对象的内存地址是否相等。如果根据equals方法，得到两个对象不相等，那么这2个对象的hashCode值可以一致（但会降低Hash表性能）；反之，equals() 方法为 true，则 hashCode 必须一致。

  ```java
  public boolean equals(Object obj) {
      return (this == obj);
  }
  ```

- getClass()：返回运行时的对象。.class是编译时确定（类属性），.getClass()是运行时才确定（实例方法）

  ```java
  List<Integer> list = new ArrayList<>();         // getClass看new不看前
  System.out.println(List.class);                 // interface java.util.List
  System.out.println(ArrayList.class);            // class java.util.ArrayList
  System.out.println(list.getClass());            // class java.util.ArrayList
  System.out.println(list.getClass().getName());  // java.util.ArrayList
  ```
- finalize()：该方法的作用是实例被垃圾回收器回收的时候触发的操作，就好比 “死前的最后一波挣扎”。

##### 1.7 ArrayList、LinkedList、Vector的区别。
Arraylist和Vector是采用数组方式存储数据，此数组元素数大于实际存储的数据以便增加插入元素，都允许直接序号索引元素，但是插入数据要涉及到数组元素移动等内存操作，所以插入数据慢，查找有下标，所以查询数据快，Vector由于使用了synchronized方法-线程安全，所以性能上比ArrayList要差，LinkedList使用双向链表实现存储，按序号索引数据需要进行向前或向后遍历，但是插入数据时只需要记录本项前后项即可，插入数据较快。

##### 1.8 Lock和Synchronized的区别
用法区别：

- synchronized：**隐式锁**，可以加在方法、类、代码块上；
- Lock：**显式锁**，需要显示指定起始位置和终止位置。

性能区别：

- synchronized：**JVM托管**，字节码控制；
- Lock：**Java代码控制**。

内部机制区别：

- synchronized：**悲观锁机制**，线程获得独占锁，其他线程只能等待当前线程阻塞；
- Lock：**乐观锁机制** ，CAS（Compare and Swap）操作（乐观锁假设认为数据一般情况下不会造成冲突，所以在数据进行提交更新的时候，才会正式对数据的冲突与否进行检测，如果发现冲突了，则让返回用户错误的信息同时进行事务回滚）


Synchronized能被中断吗？

不能，如果A不释放，B将一直等下去，不能被中断。

Lock中提供了中断的方法吗，这个方法是哪个？

lockInterruptibly();

参考：http://blog.csdn.net/natian306/article/details/18504111

##### 1.9 生产者消费者模式
生产者消费者模型具体来讲，就是在一个系统中，存在生产者和消费者两种角色，他们通过内存缓冲区进行通信，生产者生产消费者需要的资料，消费者把资料做成产品。
生产者是一堆线程，消费者是另一堆线程，内存缓冲区可以使用List数组队列，数据类型只需要定义一个简单的类就好。关键是如何处理多线程之间的协作。这其实也是多线程通信的一个范例。
在这个模型中，最关键就是内存缓冲区为空的时候消费者必须等待，而内存缓冲区满的时候，生产者必须等待。其他时候可以是个动态平衡。值得注意的是多线程对临界区资源的操作时候必须保证在读写中只能存在一个线程，所以需要设计锁的策略。

首先要实现一个阻塞队列，可以考虑用 wait/notifyAll 或 Lock/Condition 两套方案，也可以考虑直接使用concurrent 里的 BlockingQueue 来实现(BlockingQueue也是java.util.concurrent下的主要用来控制线程同步的工具。)

##### 1.10 内存模型以及分区
堆、栈（native方法栈、虚拟机栈）、程序计数器、方法区（常量池）。

![](http://gityuan.com/images/jvm/jvm_memory_1.png)

（1）线程私有区：

- 程序计数器，记录正在执行的虚拟机字节码的地址；
- 虚拟机栈：方法执行的内存区，每个方法执行时会在虚拟机栈中创建栈帧；
- 本地方法栈：虚拟机的Native方法执行的内存区；

（2）线程共享区：

- Java堆：对象分配内存的区域；
- 方法区：存放类信息、常量、静态变量、编译器编译后的代码等数据；
  - 常量池：存放编译器生成的各种字面量和符号引用，是方法区的一部分。

##### 1.11 为什么要了解GC（Garbage Collection）以及内存分配？
当需要排查各种内存溢出，内存泄漏问题时，当垃圾收集成为系统达到更高并发量的瓶颈的时候，我们需要对这些“自动化的技术”实施必要的监控和调节！

##### 1.12 一般讨论的是回收哪一部分内存？
由于程序计数器、虚拟机栈、本地方法栈3个区域随线程而生，随线程而灭；栈中的栈帧随着方法的进入和退出有条不紊的执行着出栈和入栈操作，每一个帧中分配多少内存基本上是在类结构确定下来就已知的，因此这几个区域的内存分配以及回收都有确定性，都不需要这么过多考虑回收的问题，因为等待方法结束或者线程结束时，内存自然就跟着回收了。而Java堆和方法区不一样，一个接口中的多个实现类需要的内存可能不一样，一个方法中的多个分支需要的内存也可能不一样，我们只有在程序运行期间才能知道去创建哪些对象，这部分内存的分配和回收都是动态的，垃圾收集器关注的是这一部分内存。

##### 1.13 GC的两种判定方法
在堆里面存放着Java世界里几乎所有的对象实例，垃圾收集器在对堆进行回收前，第一件事情就是要确定这些对象之中哪些还“存活”着，哪些已经死去（即不可能再被任何途径使用的对象。
**计数算法**：给对象中添加一个计数器，每当有一个地方引用它时，计数器值加1；当引用失效时，计数器值减1；任何时刻计数器值为0的对象就行不可能再被引用的；计数算法很难解决对象之间相互循环引用的问题，虚拟机不是通过引用计数算法来判断对象是否存活；
**引用链（可达性分析算法）**：通过一系列的称为“GC Roots”的对象作为起始点，从这些节点开始往下搜索，搜索所走过的路径称为引用链，当一个对象到GC Roots没有任何引用链相连时（用图论的话说就是从GC Roots到这个对象不可达），则证明此对象是不可用的；
即使是在可达性算法中不可达的对象，也可以有通过finallize（）算法拯救自己不被回收的机会；

##### 1.14 GC可达性分析算法中哪些可作为GC Roots的对象？
- 虚拟机栈（栈帧中的本地变量表）中引用的对象
- 方法区中类静态属性引用的对象
- 方法区中常量引用的对象
- 本地方法栈中JNI（Native方法）引用的对象

##### 1.15 垃圾收集算法
**标记-清除算法**：算法分为标记和清除两个阶段，首先标记出所有需要回收的对象，在标记完成后统一回收所有被标记的对象，它的标记过程就是对对象标记判定；它是最基础的收集算法，后续的收集算法都是基于这种思路的不足进行改进得到的；它的不足主要两个：第一是效率问题，标记和回收的效率都不高；另一个是空间问题，标记清除之后会产生大量的不连续的内存碎片，空间碎片太多可能会导致以后在程序运行过程中需要分配较大对象时，无法找到连续内存而不得不提前触发另外一次垃圾收集动作；
**复制算法**：为了解决效率问题，“复制”收集算法出现了；它将可用内存按容量分为大小相等的两块，每次只使用其中的一块，当这一块的内存用完了，就将还存活着的对象复制到另外一块内存上，然后把已使用过的空间一次清理掉；这样的做法就是每次都是对整个半区进行内存回收，内存分配时也不用考虑内存碎片问题，只要移动堆顶指针按顺序分配即可，实现简单运行高效。代价就是将内存缩小为原来的一半；
**标记-整理算法**：根据老年代的特点提出的，标记过程仍然和标记-清除算法一样，但后续步骤不是直接对可回收对象进行清理，而是让所有存活对象都往一端移动，然后清理掉端边界以外的内存；

##### 1.16 java堆里面的分区Eden，survival（from）to，老年代各自的特点
**Eden区**： Eden区位于Java堆的年轻代，是新对象分配内存的地方，由于堆是所有线程共享的，因此在堆上分配内存需要加锁。而Sun JDK为提升效率，会为每个新建的线程在Eden上分配一块独立的空间由该线程独享，这块空间称为TLAB（Thread Local Allocation Buffer）。在TLAB上分配内存不需要加锁，因此JVM在给线程中的对象分配内存时会尽量在TLAB上分配。如果对象过大或TLAB用完，则仍然在堆上进行分配。如果Eden区内存也用完了，则会进行一次Minor GC（young GC）。
**survival from to**：Survival区与Eden区相同都在Java堆的年轻代。Survival区有两块，一块称为from区，另一块为to区，这两个区是相对的，在发生一次Minor GC后，from区就会和to区互换。在发生Minor GC时，Eden区和Survivalfrom区会把一些仍然存活的对象复制进Survival to区，并清除内存。Survival to区会把一些存活得足够旧的对象移至年老代。
**老年代**：老年代里存放的都是存活时间较久的，大小较大的对象，因此年老代使用标记整理算法。当年老代容量满的时候，会触发一次Major GC（full GC），回收年老代和年轻代中不再被使用的对象资源。

##### 1.17 垃圾收集器
垃圾收集器是垃圾回收算法的具体实现，下图展示了HotSpot中使用的垃圾收集器：
![](https://img-blog.csdn.net/20170102225015393)
-  (7种收集器)Serial、ParNew、Parallel Scavenge、Serial Old、Parallel Old、CMS、G1；
-  新生代收集器：Serial、ParNew、Parallel Scavenge；老年代收集器：Serial Old、Parallel Old、CMS；整堆收集器：G1；
-  两个收集器间有连线，表明它们可以搭配使用；
-  并发垃圾收集和并行垃圾收集的区别
	- 并行（Parallel）：指多条垃圾收集线程并行工作，但此时用户线程仍然处于等待状态；如ParNew、Parallel Scavenge、Parallel Old；
	- 并发（Concurrent）： 指用户线程与垃圾收集线程同时执行（但不一定是并行的，可能会交替执行）；用户程序在继续运行，而垃圾收集程序线程运行于另一个CPU上；    如CMS、G1（也有并行）；

- Minor GC和Full GC的区别
	- Minor GC：又称新生代GC，指发生在新生代的垃圾收集动作；因为Java对象大多是朝生夕灭，所以Minor GC非常频繁，一般回收速度也比较快；
	- Full GC：又称Major GC或老年代GC，指发生在老年代的GC；出现Full GC经常会伴随至少一次的Minor GC（不是绝对，Parallel Sacvenge收集器就可以选择设置Major GC策略）；Major GC速度一般比Minor GC慢10倍以上；

各个收集器的作用特点请点击：[各个垃圾收集器的作用原理](https://www.cnblogs.com/ityouknow/p/5614961.html)

##### 1.18 内存分配及回收策略
Java技术体系中的**自动内存管理**最终可以归结为自动化的解决了两个问题：给对象分配内存以及回收分配给对象的内存。对象的内存分配往大方向上讲就是在堆内分配（也有可能经过JIT编译后被拆散为标量类型并间接的在栈上分配），对象主要分配在新生代的Eden区，如果启动了本地线程分配缓冲则按线程优先在TLAB上分配。少数情况下也可能直接在老年代分配，分配的规则不是百分之百固定的，其细节取决于当前使用的是哪一种垃圾收集器组合，还有虚拟机中与内存有关的相关的参数配置。

##### 1.19 Switch能否用string做参数？
不能，switch的参数类型只能是int类型

##### 1.20 equals与==的区别
“==”是一个操作符，常用于比较原生字符和对象，就原生类型boolean，float，int等类型来说比较好掌握，比较对象的时候主要是比较两个对象基于内存的引用，如果两个对象所指向的内存地址相同时就返回true；但是euqals是方法，object类中的equals方法是比较对象的内存地址，但是不同的类可以对equals进行重写，比如String类重写equals方法之后就是比较字符串的每个字符，如果每个字符都相同就返回true；

##### 1.21 Hashcode的作用
Object类提供给我们了一个Native的方法“public native int hashCode();”
1、HashCode的存在主要是为了查找的快捷性，HashCode是用来在散列存储结构中确定对象的存储地址的
2、如果两个对象equals相等，那么这两个对象的HashCode一定也相同
3、如果对象的equals方法被重写，那么对象的HashCode方法也尽量重写
4、如果两个对象的HashCode相同，不代表两个对象就相同，只能说明这两个对象在散列存储结构中，存放于同一个位置

##### 1.22 java中native关键字的作用
- native 是用做java 和其他语言（如c++）进行协作时用的，使用native关键字说明这个方法是原生函数，也就是这个方法是用C/C++语言实现的，并且被编译成了DLL，由java去调用，也就是native 后的函数的实现不是用java写的
- 既然都不是java，那就别管它的源代码了

##### 1.23 泛型
###### 1.23.1 泛型定义
泛型，即**“参数化类型”**；一提到参数，最熟悉的就是定义方法时有形参，然后调用此方法时传递实参。那么参数化类型怎么理解呢？顾名思义，就是将类型由原来的具体的类型**参数化**，类似于方法中的变量参数，此时类型也定义成参数形式（可以称之为类型形参），然后在使用/调用时传入具体的类型（类型实参）。
泛型的本质是为了**参数化类型**（在不创建新的类型的情况下，通过泛型指定的不同类型来控制形参具体限制的类型）。也就是说在泛型使用过程中，操作的数据类型被指定为一个参数，这种参数类型可以用在类、接口和方法中，分别被称为泛型类、泛型接口、泛型方法。
泛型在逻辑上可以看成是不同的类型，但是实际上都是相同的基本类型；Java中的泛型只有在编译阶段有效，在编译过程中正确检验泛型结果后，会将泛型的相关信息擦除，并且在对象进入和离开方法的边界处添加类型检查和类型转换的方法，也就是说泛型不会进入到运行阶段；
###### 1.23.2 泛型类
- 泛型类用于类的定义中，被称为泛型类。通过泛型可以完成对一组类的操作对外开放相同的接口。最典型的就是List、Map、Set等容器类；
泛型类举例：
```
//此处T可以随便写为任意标识，常见的如T、E、K、V等形式的参数常用于表示泛型
//在实例化泛型类时，必须指定T的具体类型
class FanXing<T> {
	
	//key这个成员变量的类型为T,T的类型由外部指定  
	private T key;
	//泛型构造方法形参key的类型也为T，T的类型由外部指定
	public FanXing(T key){
		this.key = key;
	}
	//泛型方法getKey的返回值类型为T，T的类型由外部指定
	public T getKey(){
		return key;
	}
}
public class Fx{
	public static void main(String[] args){
		//泛型的类型参数只能是类类型（包括自定义类），不能是简单类型
		//传入的实参类型需与泛型的类型参数类型相同，即为Integer.
		FanXing<Integer> fx = new FanXing<Integer>(1111);

		//传入的实参类型需与泛型的类型参数类型相同，即为String.
		FanXing<String> fxString = new FanXing<String>("fanxing");
		
		System.out.println("fx:"+ fx.getKey() + "fxString:" + fxString.getKey());
	}
}
```
- 定义的泛型类，就一定要传入泛型类型实参么？并不是这样，在使用泛型的时候如果传入泛型实参，则会根据传入的泛型实参做相应的限制，此时泛型才会起到本应起到的限制作用。如果不传入泛型类型实参的话，在泛型类中使用泛型的方法或成员变量定义的类型可以为任何的类型。
例如：
```
FanXing fx2 = new FanXing(1111111);
FanXing fx3 = new FanXing("nihao");
```
- **注意：**1.泛型的类型参数只能是类类型，不能是简单类型；2.不能对确切的泛型类型使用instanceof操作，下面的操作是非法的：
```
if(ex_num instanceof FanXing<Number>){
}
```
###### 1.23.3 泛型接口
泛型接口与泛型类的定义及使用基本相同。泛型接口通常被用在各种类的生产器中；
```
//定义一个泛型接口
public interface Generator<T>{
	public T next();
}
```
- 当实现泛型接口的类，未传入泛型实参时：
```
/**
 * 未传入泛型实参时，与泛型类的定义相同，在声明类的时候，需将泛型的声明也一起加到类中
 * 即：class FruitGenerator<T> implements Generator<T>{
 * 如果不声明泛型，如：class FruitGenerator implements Generator<T>，编译器会报错："Unknown class"
 */
class FruitGenerator<T> implements Generator<T>{
	public T next(){
		return null;
}
}
```
- 当实现泛型接口的类传入泛型实参时
```
public class FruitGenerator implements Generator<String>{
	private String[] fruits = new String[]{"apple","banana","pear"};

	public String next(){
		Random rand = new Random();
		return fruits[rand.nextInt(3)];
}
```
###### 1.23.4 泛型通配符
- 同一种泛型可以对应多个版本（因为参数类型是不确定的），不同版本的泛型类实例是不兼容的。
- 类型通配符一般是使用？代替具体的类型实参，注意了，此处’？’是类型实参，而不是类型形参 。重要说三遍！此处’？’是类型实参，而不是类型形参 ！ 此处’？’是类型实参，而不是类型形参 ！再直白点的意思就是，此处的？和Number、String、Integer一样都是一种实际的类型，可以把？看成所有类型的父类。是一种真实的类型。

- 可以解决当具体类型不确定的时候，这个通配符就是 ?  ；当操作类型时，不需要使用类型的具体功能时，只使用Object类中的功能。那么可以用 ? 通配符来表未知类型。

###### 1.23.5 泛型方法
泛型类，是在实例化类的时候指明泛型的具体类型；泛型方法，是在调用方法的时候指明泛型的具体类型 。
```
/**
 * 泛型方法的基本介绍
 * @param tClass 传入的泛型实参
 * @return T 返回值为T类型
 * 说明：
 *     1）public 与 返回值中间<T>非常重要，可以理解为声明此方法为泛型方法。
 *     2）只有声明了<T>的方法才是泛型方法，泛型类中的使用了泛型的成员方法并不是泛型方法。
 *     3）<T>表明该方法将使用泛型类型T，此时才可以在方法中使用泛型类型T。
 *     4）与泛型类的定义一样，此处T可以随便写为任意标识，常见的如T、E、K、V等形式的参数常用于表示泛型。
 */
public <T> T genericMethod(Class<T> tClass)throws InstantiationException ,
  IllegalAccessException{
        T instance = tClass.newInstance();
        return instance;
}
```
- 泛型方法的基本实例
```
public class GenericTest {
   //这个类是个泛型类，在上面已经介绍过
   public class Generic<T>{     
        private T key;

        public Generic(T key) {
            this.key = key;
        }

        //我想说的其实是这个，虽然在方法中使用了泛型，但是这并不是一个泛型方法。
        //这只是类中一个普通的成员方法，只不过他的返回值是在声明泛型类已经声明过的泛型。
        //所以在这个方法中才可以继续使用 T 这个泛型。
        public T getKey(){
            return key;
        }

        /**
         * 这个方法显然是有问题的，在编译器会给我们提示这样的错误信息"cannot reslove symbol E"
         * 因为在类的声明中并未声明泛型E，所以在使用E做形参和返回值类型时，编译器会无法识别。
        public E setKey(E key){
             this.key = keu
        }
        */
    }

    /** 
     * 这才是一个真正的泛型方法。
     * 首先在public与返回值之间的<T>必不可少，这表明这是一个泛型方法，并且声明了一个泛型T
     * 这个T可以出现在这个泛型方法的任意位置.
     * 泛型的数量也可以为任意多个 
     *    如：public <T,K> K showKeyName(Generic<T> container){
     *        ...
     *        }
     */
    public <T> T showKeyName(Generic<T> container){
        System.out.println("container key :" + container.getKey());
        //当然这个例子举的不太合适，只是为了说明泛型方法的特性。
        T test = container.getKey();
        return test;
    }

    //这也不是一个泛型方法，这就是一个普通的方法，只是使用了Generic<Number>这个泛型类做形参而已。
    public void showKeyValue1(Generic<Number> obj){
        Log.d("泛型测试","key value is " + obj.getKey());
    }

    //这也不是一个泛型方法，这也是一个普通的方法，只不过使用了泛型通配符?
    //同时这也印证了泛型通配符章节所描述的，?是一种类型实参，可以看做为Number等所有类的父类
    public void showKeyValue2(Generic<?> obj){
        Log.d("泛型测试","key value is " + obj.getKey());
    }

     /**
     * 这个方法是有问题的，编译器会为我们提示错误信息："UnKnown class 'E' "
     * 虽然我们声明了<T>,也表明了这是一个可以处理泛型的类型的泛型方法。
     * 但是只声明了泛型类型T，并未声明泛型类型E，因此编译器并不知道该如何处理E这个类型。
    public <T> T showKeyName(Generic<E> container){
        ...
    }  
    */

    /**
     * 这个方法也是有问题的，编译器会为我们提示错误信息："UnKnown class 'T' "
     * 对于编译器来说T这个类型并未项目中声明过，因此编译也不知道该如何编译这个类。
     * 所以这也不是一个正确的泛型方法声明。
    public void showkey(T genericObj){

    }
    */

    public static void main(String[] args) {


    }
}
```

###### 1.23.6 更详细请参考
**详细讲解请参考**：[泛型讲解](https://blog.csdn.net/s10461/article/details/53941091)
### 5.数据结构基础
##### 5.1 数组、链表等常用数据结构与集合浅析
数据结构是计算机存储、组织数据的方式，数据结构是指相互之间存在一种或多种特定关系的数据的集合； 
###### 5.1.1 集合、线性结构、树形结构、图形结构简述
**集合**：数据结构中的元素除了“同属一个集合”的相互关系外，别无其他关系；
**线性结构**：数据结构中的元素存在一对一的相互关系；
**树形结构**：数据结构中的元素存在一对多的相互关系；
**图形结构**：数据结构中的元素存在多对多的相互关系；
###### 5.1.2 数组、栈、队列
**数组**：数组是在内存中开辟一段连续的空间，并在此空间存放元素。就像是一排出租屋有100个房间，从001到100每个房间都有固定的编号，通过编号就可以快速的找到每个房间；
数组的特点是：元素类型是固定的，长度是固定的，通过角标（index）查询，查询比较快，但是插入和删除涉及到数组中元素的移动，所以增删比较慢；
![](https://img-blog.csdn.net/20170421201042882?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvdTAxMzYzMjg1NA==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/Center)
**栈**:线性结构，是一种特殊的线性表，其特殊性在于插入和删除元素只能在表的一端。后进先出。栈的存储结构有顺序栈和链栈。顺序栈中有上溢和下溢，上溢就是栈顶指针指到栈的外面，下溢本身可以表示栈为空栈；链栈则没有上溢的限制；底层用linkedlist实现；
![](https://img-blog.csdn.net/20170421201047366?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvdTAxMzYzMjg1NA==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/Center)
**顺序栈的特点**：顺序栈即栈的顺序存储结构是一组地址连续的存储单元依次存放自栈顶到栈顶的数据元素，同时附设指针top指示栈顶元素在顺序栈中的位置；由于栈的插入和删除操作具有它的特殊性，所以用顺序存储结构表示的栈并不存在插入删除数据元素时需要移动的问题，但是栈容量难以扩容的特点仍然没有解决；
**链栈的特点**：若是栈中元素的数目变化范围较大或者不清楚元素的数目，就应该考虑使用链式存储，链栈通常用一个无头结点的单链接表示；
**栈的应用**：数制转换、语法词法分析、表达式求值等；
**队列**：线性结构，也是一种运算受限的线性表，它的运算限制与栈不同，两头都有限制，插入只能在表的一头（只进不出），而删除只能在表的另一端进行（只出不进），允许插入的一头叫队尾，允许删除的一头叫队头。先进先出。底层用linkedlist实现；
![](https://img-blog.csdn.net/20170421201051375?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvdTAxMzYzMjg1NA==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/Center)
**队列的存储结构**：顺序队列和链队。顺序队列也存在上溢和下溢现象，还存在假上溢现象，为了克服假上溢现象，我们可以使用循环队列（循环队列判断队列是否为空或者为满有3种方法）；无法估计最大长度的情况下就要考虑使用链队列；
**队列的应用**：银行排队、模拟打印机缓冲区、CPU分时系统
###### 5.1.3 链表
**链表**：链表的类型有多种，单链表，双链表，有序链表等；链表是一种物理存储单元上非连续、非顺序的存储结构，数据元素的逻辑顺序是通过链表中的指针链接次序实现的。链表由一系列结点（链表中每一个元素称为结点）组成，结点可以在运行时动态生成。
可以这样理解：
有一条街，小明住在街中一角，他有小红的地址，然后小红也是住在这条街，她有小花的地址，同样小花也有别人的地址。某天我想找小红玩，但是我不知道她住哪里，我可以问小明，就知道小红住在哪里了。那么小明小红小花这些人之间的关系就组成一个链表。
![](https://img-blog.csdn.net/20170421201056163?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvdTAxMzYzMjg1NA==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/Center)
**单链表**:就是小明只是右手握着小红的地址，他只有小红一个人的地址；
**双链表**：就是小明左手握着小白的地址，右手握着小红的地址，他有两个人的地址；
**循环链表**：就是小明握有小红的地址，小红握有小花的地址，而小花又握有小明的地址，这样就形成了一个循环
**有序链表**：以某个标准，给链表的元素排序，比如比较内容大小、比较哈希值等
###### 5.1.4 二叉树
**二叉树**：二叉树是每个节点最多有两个子树的树结构。顶上的叫根结点，两边被称作“左子树”和“右子树”。二叉树常被用于实现二叉查找树和二叉堆。
![](https://img-blog.csdn.net/20170421201100297?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvdTAxMzYzMjg1NA==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/Center)
**二叉树的遍历**:遍历是对树的一种最基本的运算，所谓遍历二叉树，就是按一定的规则和顺序走遍二叉树的所有结点，使每一个结点都被访问一次，而且只被访问一次。由于二叉树是非线性结构，因此，树的遍历实质上是将二叉树的各个结点转换成为一个线性序列来表示。
二叉树的遍历大概分为四种，分别是前序遍历，中序遍历，后序遍历，按层遍历
以上图为例：
前序遍历：根-->左-->右（1-->2-->4-->5-->3-->6-->7 ）
中序遍历：左-->根-->右（4-->2-->5-->1-->3-->6-->7）
后序遍历：左-->右-->根（4-->5-->2-->6-->7-->3-->1）
按层遍历：从上到下，从左到右（1-->2-->3-->4-->5-->6-->7）

###### 5.1.5 哈希表（散列表）
散列表（Hash table，也叫哈希表），是根据关键码值(Key value)而直接进行访问的数据结构。也就是说，它通过把关键码值映射到表中一个位置来访问记录，以加快查找的速度。这个映射函数叫做散列函数，存放记录的数组叫做散列表。
可以这样理解：每个人都有自己的特征，获取这个特征的方法就叫哈希函数，一堆这样的特征被存起来就叫做哈希表；
![](https://img-blog.csdn.net/20170814210741245?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvdTAxMzYzMjg1NA==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/Center)
代表：MD5、SHA-1
作用：文件校验、数字签名
缺点：哈希表不可避免冲突（collision）现象：对不同的关键字可能得到同一哈希地址 即key1≠key2，而hash(key1)=hash(key2）。具有相同函数值的关键字对该哈希函数来说称为同义词（synonym）。

##### 5.2 数组与链表的比较
链表不需要确定长度大小，也不需要连续的内存空间，由于不是连续的内存空间，查找元素时要一个一个往后查找，比较费力，但是链表插入删除元素只需要改变链表指针指向的地址，所以增删操作比较快；相比数组只存储元素，链表的元素还要村塾其它元素的地址，内存开销比较大；

##### 5.3 二叉树与树的区别
1、二叉树，顾名思义就是每个结点最多只有两个分支，可以有一个，但最多两个；树就没有这个规则，树的一个结点可以有不确定个分支
2、二叉树的结点有左右之分；树的结点没有左右之分

##### 5.4 java集合的体系(List\Set\Map)
![](https://img-blog.csdn.net/20180308171331487)
![](https://blog.csdn.net/haovip123/article/details/45423683)
**常用集合**：List接口、Set接口、Map接口
**几个接口的特点**：
List接口（存储一组不唯一且按插入顺序排序的对象，可以操作索引）
Set接口（存储一组唯一且无序的对象）
Map接口（以键值对的形式存储元素，键是唯一的，也就是key）
**几个接口适合使用的场景**：
1、如果元素可以重复，实现List接口 
- 需要查询快
	- 线程安全
		- Vector（由数组实现，访问元素的效率比较高，删除和添加元素效率低，因为要操作大量的元素）
	-线程不安全
		- ArrayList（由数组实现，访问元素的效率比较高，删除和添加元素效率低，因为要操作大量的元素）
- 需要增删快，
    - 线程不安全
	    - LinkedList（由链表实现，插入、删除元素效率比较高，访问效率比较低）

2、如果元素需要唯一不重复，实现Set接口
- 需要查询快，
	- 线程不安全
		- HashSet（由哈希表实现，使用了Hashtable。添加、查询、删除元素的效率都很高，缺点是元素无序。通过hashcode与equals方法确保元素的唯一）
        - TreeSet（由二叉树实现。查询效率高，且元素有序的。存放自定义类型的对象需要实现 Comparable接口，重写compareTo方法，提供对象排序的方式）
        - LinkedHashSet（由哈希表实现元素的存储，由链表实现元素的顺序。添加、查询、删除元素的效率都高，且元素是有序的）
- 需要排序，
	- 线程不安全
       - TreeSet

3、通过键值对存取，实现map接口
- 需要查询快，
	- 线程不安全
	    - HashMap（由哈希表实现，使用了Hashtable。添加、查询、删除元素的效率都很高）
        - LinkedHashMap（由哈希表实现元素的存储，由链表实现元素的顺序。添加、查询、删除元素的效率都高，且元素是有序的）
        - TreeMap（由二叉树实现。查询效率高，且元素有序的。存放自定义类型的对象需要实现 Comparable接口，重写compareTo方法，提供对象排序的方式）
        - Hashtable（ 类实现一个哈希表，该哈希表将键映射到相应的值。任何非 null 对象都可以用作键或值。为了成功地在哈希表中存储和获取对象，用作键的对象必须实现 hashCode 方法和 equals 方法）

##### 5.5 ConcurrentHashMap
##### 5.6 线程安全和线程不安全
线程安全就是多线程访问时，采用了加锁机制，当一个线程访问该类的某个数据时，进行保护，其他线程不能进行访问直到该线程读取完，其他线程才可使用。不会出现数据不一致或者数据污染。
线程不安全就是不提供数据访问保护，有可能出现多个线程先后更改数据造成所得到的数据是脏数据

##### 5.7 线程同步synchronsized
将操作共享数据的代码行作为一个整体，同一时间只允许一个线程执行，执行过程中其他线程不能参与执行。目的是为了防止多个线程访问一个数据对象时，对数据造成的破坏。
**1、同步方法（synchronized）**:对共享资源进行访问的方法定义中加上synchronized关键字修饰，使得此方法称为同步方法。可以简单理解成对此方法进行了加锁，其锁对象为当前方法所在的对象自身。多线程环境下，当执行此方法时，首先都要获得此同步锁（且同时最多只有一个线程能够获得），只有当线程执行完此同步方法后，才会释放锁对象，其他的线程才有可能获取此同步锁，以此类推...
**2、同步代码块（synchronized）**：使用同步方法时，使得整个方法体都成为了同步执行状态，会使得可能出现同步范围过大的情况，于是，针对需要同步的代码可以直接另一种同步方式——同步代码块来解决，格式如下：
```
synchronized (obj) {        
     // ....
}
```
其中，obj为锁对象，因此，选择哪一个对象作为锁是至关重要的。一般情况下，都是选择此共享资源对象作为锁对象。
**3、同步锁（Lock）**：使用Lock对象同步锁可以方便地解决选择锁对象的问题，唯一需要注意的一点是Lock对象需要与资源对象同样具有一对一的关系。Lock对象同步锁一般格式为：
```
class X {
    // 显示定义Lock同步锁对象，此对象与共享资源具有一对一关系
    private final Lock lock = new ReentrantLock();
    
    public void m(){
        // 加锁
        lock.lock();
        
        //...  需要进行线程安全同步的代码
        
        // 释放Lock锁
        lock.unlock();
    }
}
```
##### 5.8 排序算法总结
我们常说的排序算法往往指的是内部排序算法，即数据记录在内存中进行排序；
排序大体可以分为比较排序和非比较排序两种，比较排序主要有冒泡排序、选择排序、插入排序、归并排序、堆排序、快速排序等，非比较排序主要有计数排序、基数排序、桶排序等；
![](https://images2015.cnblogs.com/blog/739525/201605/739525-20160503202729044-614991035.jpg)
###### 5.8.1 冒泡排序
重复的走访要排序的元素，依次比较相邻的两个元素，如果反序则交换，直到没有元素需要交换，每一次排序都会把最大（或最小）的元素排到最前面。时间复杂度分析：在最好情况下数组本身有序，只需要进行n-1次比较，时间复杂度为O(n);最坏情况下数组为逆序，此时需要比较n*（n-1）/2,时间复杂度为O（n2）；
###### 5.8.2 简单选择排序
一趟简单选择排序的操作为通过n-i次关键字间的比较，从n-i+1个记录中选出关键字最小的记录并和第i个记录交换之。选择排序每遍历一次都记住了当前最小（大）元素的位置，最后仅需一次交换操作就可将其放到合适位置。简单选择排序的最大特点是：交换移动数据的次数相当少，最好的情况交换0次，最坏的情况交换n-1次，适用于数组个数不多，但每个数组元素较大的情况；时间复杂度分析：无论是最好最差情况，比较次数都是n（n-1）/2，时间复杂度为O（n2）；在性能上略优于冒泡排序；
###### 5.8.3 直接插入排序
原理类似于抓扑克牌，对于未排序数据（右手抓到的牌），在已排序序列	（左手已经排好序的手牌）中从后向前扫描插入相应位置。具体算法描述如下：第一个元素开始，可以认为此元素已经排好序，从第二个元素开始在已排序的序列中从后向前扫描，直到扫描到某个元素小于或等于新元素，然后将新元素插入到该位置后，重复此步骤直至排序结束；时间复杂度分析：最好情况是在本身有序的情况下，比较了n-1次，没有移动的记录，时间复杂度为O（n）；最坏情况是在逆序情况下，比较了n（n-1）/2，移动了(n+2)(n-2)/2次，时间复杂度为O（n2）；平均比较移动次数为n2/4,故时间复杂度为O(n2)。
**改进排序算法**
###### 5.8.4 二分插入排序
如果比较操作的代价比交换操作大的话，可以采用二分查找法来减少比较的次数，我们称之为二分插入排序；是直接插入排序的一个改进，区别是在有序区中查找新元素插入位置时，为了减少元素之间比较的次数，采用二分查找法进行插入位置的确定。
###### 5.8.5希尔排序
插入排序算法的更高效改进，也叫缩小增量排序。简单的直接插入排序中，如果待排序序列是正序时，时间复杂度为O（n）；如果待排序序列是基本有序的，使用直接插入排序的效率就比较高；希尔排序就利用了这个特点，其基本思想是先将整个待排记录序列分割成为若干子序列分别进行直接插入排序，待整个序列中的记录基本有序时再对全体记录进行一次直接插入排序。希尔排序的子序列的构成不是简单的“逐段分割”，而是将相隔某个“增量”的记录组成一个子序列，增量是逐渐减小的，所以也叫缩小增量排序。希尔排序的时间是所取“增量”的函数，这涉及数学上的一些难题，但是在大量实验基础上推出当n在某个范围时，时间复杂度可达到O（n1.3）；
###### 5.8.6 堆排序
是指利用堆这种数据结构所设计的一种选择排序算法。堆是一种近似完全二叉树的一种结构（通常堆是通过一维数组来实现的），并满足性质：以最大堆为例（也叫大根堆、大顶堆），其中父节点的值总是大于它的孩子节点。若在输出堆顶的最小值之后，使得剩余n-1个元素的序列重又建成一个堆，则得到n个元素中的次小值。如此反复执行，便能得到一个有序序列，这个过程称之为堆排序；堆排序方法对记录数较小的文件并不值得提倡，但是对n较大的文件还是很有效的，因为其运行时间主要耗费在建初始堆和调整建新堆时进行的反复筛选上，构建大根堆的时间复杂度为O（n），重建堆的时间复杂度为O（nlogn），无论最好，最坏还是平均时间复杂度均为O（nlogn），空间复杂度只需要一个暂存单元，由于记录的比较与交换是跳跃式进行故是一种不稳定的算法，由于初始构建堆所需要的比较次数较多，所以不适合带排序序列个数较少的情况；
###### 5.8.7 归并排序
归并排序是另外一种不同的排序方法，使用了递归分治的思想，其思想是“先递归划分子问题，然后合并结果”。把待排序序列看成两个有序的子序列，然后合并两个子序列，然后把子序列看成由两个有序序列组成，然后合并。。。倒着来看就是先两两合并再四四合并。。。最终形成有序序列。空间复杂度为O（n），时间复杂度为O（nlogn），归并排序为稳定的排序算法；
###### 5.8.8 快速排序
是冒泡排序的一种改进，其基本思想是通过一趟排序将待排记录分割成独立的两部分，其中一部分记录的关键字均比另一部分记录关键字小，然后再分别对两部分记录进行排序，从而达到整个序列有序。快速排序的最优与平均时间复杂度都为O（nlogn），最坏时间复杂度为O（n2），空间复杂度为O（logn），快速排序在所有时间复杂度为O（nlogn）的排序算法中性能最好；

##### 6. 二叉树、B+树、AVL树、红黑树、哈夫曼树
###### 6.1 avl树
平衡二叉树，一般是用平衡因子差值决定并通过旋转来实现，左右子树树高差不超过1，那么和红黑树比较它是严格的平衡二叉树，平衡条件非常严格（树高差只有1），只要插入或删除不满足上面的条件就要通过旋转来保持平衡。由于旋转是非常耗费时间的。我们可以推出AVL树适合用于插入删除次数比较少，但查找多的情况。

###### 6.2 红黑树
平衡二叉树，通过对任何一条从根到叶子的简单路径上各个节点的颜色进行约束，确保没有一条路径会比其他路径长2倍，因而是近似平衡的。所以相对于严格要求平衡的AVL树来说，它的旋转保持平衡次数较少。用于搜索时，插入删除次数多的情况下我们就用红黑树来取代AVL。
红黑树应用比较广泛：
·        广泛用在C++的STL中。map和set都是用红黑树实现的。
·        著名的linux进程调度Completely Fair Scheduler,用红黑树管理进程控制块。
·        epoll在内核中的实现，用红黑树管理事件块
·        nginx中，用红黑树管理timer等
·        Java的TreeMap实现

###### 6.3 B、B+树
它们特点是一样的，是多路查找树，一般用于数据库中做索引，因为它们分支多层数少，因为磁盘IO是非常耗时的，而像大量数据存储在磁盘中所以我们要有效的减少磁盘IO次数避免磁盘频繁的查找。
B+树是B树的变种树，有n棵子树的节点中含有n个关键字，每个关键字不保存数据，只用来索引，数据都保存在叶子节点。是为文件系统而生的。
        B+树相对B树磁盘读写代价更低：因为B+树非叶子结点只存储键值，单个节点占空间小，索引块能够存储更多的节点，从磁盘读索引时所需的索引块更少，所以索引查找时I/O次数较B-Tree索引少，效率更高。而且B+Tree在叶子节点存放的记录以链表的形式链接，范围查找或遍历效率更高。Mysql InnoDB用的就是B+Tree索引。

###### 6.4 哈夫曼树
给定n个权值作为n个叶子结点，构造一棵二叉树，若带权路径长度达到最小，称这样的二叉树为最优二叉树，也称为哈夫曼树(Huffman Tree)。哈夫曼树是带权路径长度最短的树，权值较大的结点离根较近。

##### 7. 搜索算法
广度优先搜索（BFS）：广度优先搜索（BFS）类似于二叉树的层序遍历算法，它的基本思想是：首先访问起始顶点v，然后由v出发，依次访问v的各个未被访问过的邻接顶点w1,w2,w3….wn，然后再依次访问w1，w2,…,wi的所有未被访问过的邻接顶点，再从这些访问过的顶点出发，再访问它们所有未被访问过的邻接顶点….以此类推，直到途中所有的顶点都被访问过为止。类似的想法还将应用与Dijkstra单源最短路径算法和Prim最小生成树算法。
　广度优先搜索是一种分层的查找过程，每向前走一步可能访问一批顶点，不像深度优先搜索那样有回退的情况（另一篇博客会介绍），因此它不是一个递归的算法，为了实现逐层的访问，算法必须借助一个辅助队列并且以非递归的形式来实现。
实例解析：
![](https://img-blog.csdn.net/20170427210818719?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvbTBfMzczMTY5MTc=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)
假设从a顶点开始访问，a先入队。此时队列非空，取出队头元素a，由于b，c和a直接相邻且未被访问过，于是依次访问b，c，并且b，c依次入队。队列非空，取出队头元素b，依次访问与b相邻且未被访问的顶点d，e，并且将d，e入队（注意：a与b也邻接，但是a已经访问过，就不会再访问了）。此时队列非空，取出队头元素c，访问与c邻接且未被访问过的顶点f，g，并且将f，g入队。此时，取出队头元素d，但与d邻接且为被访问的顶点为空，故不再进行任何操作，继续取出对头元素e，将h入队….当最后取出队头元素h后，队列为空，从而循环自动跳出，遍历的结果为abcdefgh。
**BFS算法性能分析**:无论是邻接表还是邻接矩阵的存储访问，BFS算法都需要借助一个辅助队列Q，n个顶点都需要入队依次，在最坏的情况下，空间复杂度为O（|V|）。 
　　当采用邻接表存储方式时，每个顶点均需要搜索依次（或入队依次），故时间复杂度为O（|V|），再搜索任一顶点时，每条边至少访问依次，故时间复杂度为O(|E|)，算法的总时间复杂度为O(|V|+|E|)；当采用邻接矩阵存储方式的时候，查找每个顶点的邻接点所需时间为O（|V|），故算法总的时间复杂度为O(|V|²)。
深度优先搜索（DFS）：　与广度优先搜索算法不同，深度优先搜索算法类似与树的先序遍历。这种搜索算法所遵循的搜索策略是尽可能“深”地搜索一个图。它的基本思想如下：首先访问图中某一个起始顶点v，然后由v出发，访问与v相邻且未被访问的任一顶点w1,再访问与w1邻接且未被访问的任一顶点w2，….重复上述过程。当不能再继续向下访问时，依次退回到最近被访问的顶点，若它还有邻接顶点未被访问过，则从该点开始继续上述搜索过程，直到图中所有顶点均被访问过为止;
**实例分析：**
![](https://img-blog.csdn.net/20170427210818719?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvbTBfMzczMTY5MTc=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)
首先访问a，并置a为已经访问；然后访问与a邻接且未被访问的顶点b，置b为已经访问，然后访问与b邻接且未被访问的顶点d，置d为已经访问。此时d已经没有未被访问过的邻接点，这时候返回上一个访问过的顶点b，访问与其邻接且未被访问的顶点e，置e为已经访问……。依此类推，直到途中所有的顶点都被访问一次且仅仅被访问一次，遍历结果为abdehcfg。
**DFS算法的性能分析:**
　　DFS算法是一个递归算法，需要借助一个递归工作栈，所以它的空间复杂度是O(|V|)。 
　　遍历图的过程实际上是对每个顶点查找其邻接点的过程，其耗费的时间取决于所采用的存储结构，当以邻接矩阵表示时，查找每个顶点的临界点所需时间为O（|V|），故总的时间复杂度为O(|V|²)。当以邻接表表示时，查找所有顶点的邻接点所需时间为O(|E|)，访问顶点所需时间为O(|V|),此时，总的时间复杂度为O(|V|+|E|)。
### 4. SSM框架
##### 4.1 简单说一下对SpringMVC的理解
- 它是基于组件技术的.全部的应用对象,无论控制器和视图,还是业务对象之类的都是java组件.并且和Spring提供的其他基础结构紧密集成.
- 不依赖于Servlet API(目标虽是如此,但是在实现的时候确实是依赖于Servlet的)
- 可以任意使用各种视图技术,而不仅仅局限于JSP
- 支持各种请求资源的映射策略
- 它应是易于扩展的

##### 4.2  SpringMVC的工作流程
![](https://img-blog.csdn.net/20170119141709623?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvSmFtZXNfc2h1/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)

1. 用户发送请求至前端控制器DispatcherServlet
2. DispatcherServlet收到请求调用HandlerMapping处理器映射器。
3. 处理器映射器根据请求url找到具体的处理器，生成处理器对象及处理器拦截器(如果有则生成)一并返回给DispatcherServlet。
4. DispatcherServlet通过HandlerAdapter处理器适配器调用处理器
5. 执行处理器(Controller，也叫后端控制器)。
6. Controller执行完成返回ModelAndView
7. HandlerAdapter将controller执行结果ModelAndView返回给DispatcherServlet
8. DispatcherServlet将ModelAndView传给ViewReslover视图解析器
9. ViewReslover解析后返回具体View
10. DispatcherServlet对View进行渲染视图（即将模型数据填充至视图中）。
11. DispatcherServlet响应用户

##### 4.3 springMVC 与 struts2 的区别
1. springmvc的入口是一个servlet即前端控制器，而struts2入口是一个filter过滤器。
2. springmvc是基于方法开发(一个url对应一个方法)，请求参数传递到方法的形参，可以设计为单例或多例(建议单例)，struts2是基于类开发，传递参数是通过类的属性，只能设计为多例。
3. Struts采用值栈存储请求和响应的数据，通过OGNL存取数据， springmvc通过参数解析器是将request请求内容解析，并给方法形参赋值，将数据和视图封装成ModelAndView对象，最后又将ModelAndView中的模型数据通过reques域传输到页面。Jsp视图解析器默认使用jstl。

##### 4.4 简单说一下你对mybatis的理解
1. mybatis配置
2. SqlMapConfig.xml，此文件作为mybatis的全局配置文件，配置了mybatis的运行环境等信息。
3. mapper.xml文件即sql映射文件，文件中配置了操作数据库的sql语句。此文件需要在SqlMapConfig.xml中加载。
4. 通过mybatis环境等配置信息构造SqlSessionFactory即会话工厂
5. 由会话工厂创建sqlSession即会话，操作数据库需要通过sqlSession进行。
6. mybatis底层自定义了Executor执行器接口操作数据库，Executor接口有两个实现，一个是基本执行器、一个是缓存执行器。
7. Mapped Statement也是mybatis一个底层封装对象，它包装了mybatis配置信息及sql映射信息等。mapper.xml文件中一个sql对应一个Mapped Statement对象，sql的id即是Mapped statement的id。
8. Mapped Statement对sql执行输入参数进行定义，包括HashMap、基本类型、pojo，Executor通过Mapped Statement在执行sql前将输入的java对象映射至sql中，输入参数映射就是jdbc编程中对preparedStatement设置参数。
9. Mapped Statement对sql执行输出结果进行定义，包括HashMap、基本类型、pojo，Executor通过Mapped Statement在执行sql后将输出结果映射至java对象中，输出结果映射过程相当于jdbc编程中对结果的解析处理过程。

##### 4.5 spring框架的优势
- 轻量：Spring 是轻量的，基本的版本大约2MB。
- 控制反转：Spring通过控制反转实现了松散耦合，对象们给出它们的依赖，而不是创建或查找依赖的对象们。
- 面向切面的编程(AOP)：Spring支持面向切面的编程，并且把应用业务逻辑和系统服务分开。
- 容器：Spring 包含并管理应用中对象的生命周期和配置。
- MVC框架：Spring的WEB框架是个精心设计的框架，是Web框架的一个很好的替代品。
- 事务管理：Spring 提供一个持续的事务管理接口，可以扩展到上至本地事务下至全局事务（JTA）。
- 异常处理：Spring 提供方便的API把具体技术相关的异常（比如由JDBC，Hibernate or JDO抛出的）转化为一致的unchecked 异常。

##### 4.6 核心容器（应用上下文) 模块
这是基本的Spring模块，提供spring 框架的基础功能，BeanFactory 是 任何以spring为基础的应用的核心。Spring 框架建立在此模块之上，它使Spring成为一个容器。

##### 4.7 BeanFactory – BeanFactory 实现举例
Bean 工厂是工厂模式的一个实现，提供了控制反转功能，用来把应用的配置和依赖从正真的应用代码中分离。
最常用的BeanFactory 实现是XmlBeanFactory 类

##### 4.8 XMLBeanFactory 
最常用的就是org.springframework.beans.factory.xml.XmlBeanFactory ，它根据XML文件中的定义加载beans。该容器从XML 文件读取配置元数据并用它去创建一个完全配置的系统或应用。

##### 4.9 spring常见面试题
[spring常见面试题1](http://www.cnblogs.com/liangyihui/p/5917773.html )
[spring常见面试题2](http://www.importnew.com/19538.html)

##### 4.10 springMVC常见面试题
[springMVC常见面试题1](http://www.cnblogs.com/wang-meng/p/5701987.html )
[springMVC常见面试题2](http://blog.csdn.net/xinghuo0007/article/details/53463897 )

##### 4.11 mybatis常见面试题
[mybatis常见面试题1](http://blog.csdn.net/eaphyy/article/details/71190441 )
[mybatis常见面试题2](http://www.cnblogs.com/huajiezh/p/6415388.html )

##### 4.12 AOP
面向切面编程：是指在程序运行期间将某段代码，动态的切入到某个类的指定方法的指定位置的这种编程思想叫做面向切面编程。
AOP编程操作的主要对象是切面(aspect)，而切面模块化横切关注点。
在应用AOP编程时，仍然需要定义公共功能，但可以明确的定义这个功能应用在哪里，以什么方式应用，并且不必修改受影响的类。这样一来横切关注点就被模块化到特殊的类里——这样的类我们通常称之为“切面”。
AOP的好处：
每个事物逻辑位于一个位置，代码不分散，便于维护和升级
业务模块更简洁，只包含核心业务代码

##### 4.13 IOC
Ioc—Inversion of Control，即“控制反转”，不是什么技术，而是一种设计思想。在Java开发中，Ioc意味着将你设计好的对象交给容器控制，而不是传统的在你的对象内部直接控制。如何理解好Ioc呢？理解好Ioc的关键是要明确“谁控制谁，控制什么，为何是反转（有反转就应该有正转了），哪些方面反转了”，那我们来深入分析一下：

　　●谁控制谁，控制什么：传统Java SE程序设计，我们直接在对象内部通过new进行创建对象，是程序主动去创建依赖对象；而IoC是有专门一个容器来创建这些对象，即由Ioc容器来控制对 象的创建；谁控制谁？当然是IoC 容器控制了对象；控制什么？那就是主要控制了外部资源获取（不只是对象包括比如文件等）。

　　●为何是反转，哪些方面反转了：有反转就有正转，传统应用程序是由我们自己在对象中主动控制去直接获取依赖对象，也就是正转；而反转则是由容器来帮忙创建及注入依赖对象；为何是反转？因为由容器帮我们查找及注入依赖对象，对象只是被动的接受依赖对象，所以是反转；哪些方面反转了？依赖对象的获取被反转了。

##### 4.14 Hibernate的缓存等级及其特点

![IOC](https://blog.csdn.net/qq_22654611/article/details/52606960)
### 2.操作系统

##### 2.1 什么是进程和线程？
- 进程是指在系统中能够独立运行并作为资源分配的基本单位，它是由一组机器指令、数据和堆栈组成的，是一个能够独立运行的活动实体；进程有就绪状态、执行状态和等待状态（或阻塞状态）三个状态；
- 线程是进程中的一个相对独立的可执行单元，是执行运算的最小单位，亦即执行处理调度的基本单位，如果把进程理解为逻辑上操作系统所完成的任务，那么线程就表示完成该任务需要完成的许多子任务之一。线程可以在处理器上独立调度执行，这样在多处理器环境下就允许几个线程各自在单独处理器上执行；举个例子线程就是火车上的每个车厢，进程就是火车；
**线程的实质**：1.线程是进程内的一个相对独立的可执行的单元。若把进程称之为任务的话，那么线程则是应用中的一个子任务的执行；2.由于线程是被调度的基本单元，而进程不是调度单元，所以每个进程在创建时至少需要同时为该进程创建一个线程，即进程中至少需要一个或者一个以上的线程，否则该进程无法被调度执行；3.进程是被分给并拥有资源的基本单位。同一进程内的多个线程共享该进程的资源，但线程并不拥有资源，只是使用它们；4.线程是操作系统中基本调度单元，因此线程中应该包含调度所需要的必要信息，且在生命周期内有状态变化；5.由于线程之间共享资源（数据和文件等），所以线程之间需要同步和通信机制，且需要时线程可以创建其它线程，但线程之间不存在父子关系；
**线程机制的优点**：多线程运行在同一个进程的相同的地址空间内，和采用多进程相比有如下优点：1.创建和撤销线程的开销比进程要少，创建线程时只需要创建线程控制表相应的表目或有关队列，但是创建进程时需要创建PCB和初始化，进入有关进程队列需要建立它的地址空间和所需要的资源等等；
3.CPU在线程之间开关时的开销远比在进程之间开关少的多，因为开关线程都在同一个地址空间内，只需要修改线程控制表或队列，不涉及地址空间和其他工作；3.线程机制也增加了通讯的有效性，进程间的通讯往往要求有内核的参与，以提供通讯机制和保护机制，而线程间的通讯是在同一进程内的地址空间内，共享主存和文件无需内核的参与；
##### 2.2 进程和线程的区别
-  进程独占内存，线程共享内存
-  进程是资源分配单位，线程是CPU调度单位
-  线程切换与进程切换无关，进程切换线程一定切换
-  进程切换的开销远比线程切换的开销大

##### 2.3 死锁的必要条件，怎么处理死锁？
**什么是死锁**：死锁是指多个进程因竞争资源而造成的一种僵局（互相等待），若无外力作用，这些进程都将无法推进。
**死锁产生的原因**：1.系统资源的竞争：系统资源的竞争导致系统资源不足以及资源分配不同导致死锁；2.进程运行推进顺序不合适：进程在运行过程中，请求和释放资源的顺序不当导致死锁；如果系统资源充足，进程的资源都能够得到满足，死锁出现的可能性就比较低，否则就会因为争夺有限的资源而陷入死锁，其次进程运行推进顺序与速度不同也可能产生死锁；
**死锁产生的四个必要条件**：1.互斥条件：一个资源每次只能被一个进程所占有，如果某一时间段内某资源仅为一个进程所占有，此时若有其它进程请求该资源，那么请求进程只能等待；2.请求保持条件：进程已经保持了至少一个资源，但是又提出了新的资源要求，而该资源已被其它进程占有，此时请求进程被阻塞，但是对自己已获得的资源保持不放；3.不可抢占条件：进程所获得的资源在未使用完毕之前，不能被其它进程强行夺走，即只能由获得该资源的进程自己释放（只能是主动释放）；4.循环等待条件：若干进程之间形成首尾相接循环等待资源的关系；
**死锁的避免和预防**：1.忽略该问题。例如鸵鸟算法，该算法可以应用在极少发生死锁的情况下，为什么叫鸵鸟算法，因为鸵鸟看到危险就选择把头埋在地底下，就假装看不见。2.检测死锁并恢复。3.仔细的对资源进行分配以避免死锁。使用银行家算法，所谓银行家算法是指在分配资源之前先看清楚，资源分配后是否会产生死锁，如果会产生死锁则不予分配；4.通过破坏死锁产生的四个必要条件之一来防止死锁的产生。

##### 2.3  什么是虚拟内存
操作系统中内存管理技术的一种。它使得应用程序认为它拥有连续的可用的内存（一个连续完整的地址空间），而实际上，它通常是被分隔成多个物理内存碎片，还有部分暂时存储在外部磁盘存储器上，在需要时进行数据交换。

写过完善的程序的程序员都会有一个感触，就是一个项目的程序虽然非常多，但是其实有一部分程序并不经常执行，或者基本上没有执行过，比如说异常处理、错误处理等，那么这些程序使得我们可以只需要加载需要执行的部分，从而减少了内存使用。从而，我们可以构造一个大的虚拟内存空间，然后将其映射到较小的物理内存。这个大的虚拟内存空间存储我们进程的所有信息，而当执行进程时，我们只加载需要执行的部分，需要什么再加载什么。这里就需要采用一定的技术，比如按需调页、页面置换、帧分配等，使得进程的执行可以在虚拟内存和物理内存之间进行协调，完成整个程序的执行。

**虚拟内存技术的优点**：虚拟内存可以大于物理内存，一般为物理内存的1.5倍到3倍，从而可以运行比物理内存大的程序，进而使得更多的程序可以同时执行，提高了多道程序的程度，增加了CPU的使用率，并且使得进程之间的独立性得到了更好的体现；

##### 2.4 段页式存储
调度方式有分页式、段式、段页式3种。页式调度是将逻辑和物理地址空间都分成固定大小的页。主存按页顺序编号，而每个独立编址的程序空间有自己的页号顺序，通过调度辅存中程序的各页可以离散装入主存中不同的页面位置，并可据表一一对应检索。页式调度的优点是页内零头小，页表对程序员来说是透明的，地址变换快，调入操作简单；缺点是各页不是程序的独立模块，不便于实现程序和数据的保护。段式调度是按程序的逻辑结构划分地址空间，段的长度是随意的，并且允许伸长，它的优点是消除了内存零头，易于实现存储保护，便于程序动态装配；缺点是调入操作复杂。将这两种方法结合起来便构成段页式调度。在段页式调度中把物理空间分成页，程序按模块分段，每个段再分成与物理空间页同样小的页面。段页式调度综合了段式和页式的优点。其缺点是增加了硬件成本，软件也较复杂。大型通用计算机系统多数采用段页式调度。

##### 2.5 虚拟地址、逻辑地址、线性地址、物理地址的区别
- 虚拟地址是由程序产生的由段选择符和段内偏移地址组成的地址。这两部分组成的地址并没有直接访问物理内存，而是要通过分段地址的变换处理后才会对应到相应的物理内存地址。
- 逻辑地址指由程序产生的段内偏移地址。有时把逻辑地址当成虚拟地址，两者并没有明确的界限。
- 线性地址是指虚拟地址到物理地址变换的中间层， 是处理器可寻址的内存空间（称为线性地址空间）中的地址。程序代码会产生逻辑地址，或者说段中的偏移地址，加上相应段基址就生成了一个线性地址。如果启用了分页机制，那么线性地址可以再经过变换产生物理地址。若是没有采用分页机制，那么线性地址就是物理地址。
- 物理地址是指现在 CPU 外部地址总线上的寻址物理内存的地址信号，是地址变换的最终结果。
- 虚拟地址到物理地址的转换方法是体系结构相关的，一般分段与分页两种方式。

##### 2.6 线程通信（wait()/notify()/notifyAll()）
wait()：导致当前线程等待并使其进入到等待阻塞状态。直到其他线程调用该同步锁对象的notify()或notifyAll()方法来唤醒此线程。

- void wait(long timeout) -- 导致当前线程等待，直到其他线程调用此对象的 notify() 方法或 notifyAll() 方法，或者超过指定的时间量。 
- void wait(long timeout, int nanos) -- 导致当前线程等待，直到其他线程调用此对象的 notify() 方法或 notifyAll() 方法，或者其他某个线程中断当前线程，或者已超过某个实际时间量。

notify()：唤醒在此同步锁对象上等待的单个线程，如果有多个线程都在此同步锁对象上等待，则会任意选择其中某个线程进行唤醒操作，只有当前线程放弃对同步锁对象的锁定，才可能执行被唤醒的线程。

notifyAll()：唤醒在此同步锁对象上等待的所有线程，只有当前线程放弃对同步锁对象的锁定，才可能执行被唤醒的线程。

　　这三个方法主要都是用于多线程中，但实际上都是Object类中的本地方法。因此，理论上，任何Object对象都可以作为这三个方法的主调，在实际的多线程编程中，只有同步锁对象调这三个方法，才能完成对多线程间的线程通信。

注意点：

1.wait()方法执行后，当前线程立即进入到等待阻塞状态，其后面的代码不会执行；

2.notify()/notifyAll()方法执行后，将唤醒此同步锁对象上的（任意一个-notify()/所有-notifyAll()）线程对象，但是，此时还并没有释放同步锁对象，也就是说，如果notify()/notifyAll()后面还有代码，还会继续进行，知道当前线程执行完毕才会释放同步锁对象；

3.notify()/notifyAll()执行后，如果右面有sleep()方法，则会使当前线程进入到阻塞状态，但是同步对象锁没有释放，依然自己保留，那么一定时候后还是会继续执行此线程，接下来同2；

4.wait()/notify()/nitifyAll()完成线程间的通信或协作都是基于不同对象锁的，因此，如果是不同的同步对象锁将失去意义，同时，同步对象锁最好是与共享资源对象保持一一对应关系；

5.当wait线程唤醒后并执行时，是接着上次执行到的wait()方法代码后面继续往下执行的。
##### 2.7 java中怎么创建线程
创建线程有两种方式：
（1）继承 Thread 类，扩展线程。
（2）实现 Runnable 接口。

继承Thread类的方式有它固有的弊端，因为Java中继承的单一性，继承了Thread类就不能继承其他类了；同时也不符合继承的语义，Dog跟Thread没有直接的父子关系，继承Thread只是为了能拥有一些功能特性。

而实现Runnable接口，①避免了单一继承的局限性，②同时更符合面向对象的编程方式，即将线程对象进行单独的封装，③而且实现接口的方式降低了线程对象(Dog)和线程任务(run方法中的代码)的耦合性，④如上面所述，可以使用同一个Dog类的实例来创建并开启多个线程，非常方便的实现资源的共享。实际上Thread类也是实现了Runnable接口。实际开发中多是使用实现Runnable接口的方式。

##### 2.8 启动一个线程是调用run()还是start()方法？
答：启动一个线程是调用start()方法，使线程所代表的虚拟处理机处于可运行状态，这意味着它可以由JVM 调度并执行，这并不意味着线程就会立即运行。run()方法是线程启动后要进行回调（callback）的方法。

##### 2.9 线程类的一些常用的方法
- sleep(): 强迫一个线程睡眠Ｎ毫秒，是一个静态方法，调用此方法要处理InterruptedException异常；
- join():  让一个线程等待另一个线程完成才继续执行；
- yeild(): 线程让步，暂停当前正在执行的线程对象让出CPU资源，将当前线程从运行状态转换到就绪状态并执行其他优先级相同或更高的线程；
- isAlive(): 判断一个线程是否存活。 
- activeCount(): 程序中活跃的线程数。 
- enumerate(): 枚举程序中的线程。 
- currentThread(): 得到当前线程。 
- isDaemon(): 一个线程是否为守护线程。 
- setDaemon(): 设置一个线程为守护线程。(用户线程和守护线程的区别在于，是否等待主线程依赖于主线程结束而结束) 
- setName(): 为线程设置一个名称。 
- setPriority(): 设置一个线程的优先级。
- wait()：使一个线程处于等待（阻塞）状态，并且释放所持有的对象的锁；
- notify()：唤醒一个处于等待状态的线程，当然在调用此方法的时候，并不能确切的唤醒某一个等待状态的线程，而是由JVM确定唤醒哪个线程，而且与优先级无关；
- notityAll()：唤醒所有处于等待状态的线程，该方法并不是将对象的锁给所有线程，而是让它们竞争，只有获得锁的线程才能进入就绪状态；

##### 2.10 wait()/sleep()方法比较
共同点： 
1). 他们都是在多线程的环境下，sleep()方法和对象的wait()方法都可以让线程暂停执行，都可以在程序的调用处阻塞指定的毫秒数，并返回。 
2). wait()和sleep()都可以通过interrupt()方法打断线程的暂停状态 ，从而使线程立刻抛出InterruptedException。 
如果线程A希望立即结束线程B，则可以对线程B对应的Thread实例调用interrupt方法。如果此刻线程B正在wait/sleep /join，则线程B会立刻抛出InterruptedException，在catch() {} 中直接return即可安全地结束线程。 需要注意的是，InterruptedException是线程自己从内部抛出的，并不是interrupt()方法抛出的。对某一线程调用 interrupt()时，如果该线程正在执行普通的代码，那么该线程根本就不会抛出InterruptedException。但是，一旦该线程进入到 wait()/sleep()/join()后，就会立刻抛出InterruptedException 。 

不同点： 
1). Thread类的方法：sleep(),yield()等 
     Object类的方法：wait()和notify()等 
2). 每个对象都有一个锁来控制同步访问。Synchronized关键字可以和对象的锁交互，来实现线程的同步。 
- sleep()方法让当前线程暂停执行指定的时间，将执行机会（CPU）让给其他线程，但是对象的锁依然保持，休眠结束后线程会自动回到就绪状态;
- wait()方法导致当前线程放弃对象的锁（线程暂停执行），进入对象的等待池（wait pool），只有调用对象的notify()方法（或notifyAll()方法）时才能唤醒等待池中的线程进入等锁池（lock pool），如果线程重新获得对象的锁就可以进入就绪状态。

3). wait，notify和notifyAll只能在同步控制方法或者同步控制块里面使用，而sleep可以在任何地方使用 
4). sleep必须捕获异常，而wait，notify和notifyAll不需要捕获异常
所以sleep()和wait()方法的最大区别是：
　　sleep()睡眠时，保持对象锁，仍然占有该锁；
　　而wait()睡眠时，释放对象锁。
但是wait()和sleep()都可以通过interrupt()方法打断线程的暂停状态，从而使线程立刻抛出InterruptedException（但不建议使用该方法）。

##### 2.11 yield()/sleep()方法什么区别
① sleep()方法给其他线程运行机会时不考虑线程的优先级，因此会给低优先级的线程以运行的机会；yield()方法只会给相同优先级或更高优先级的线程以运行的机会；
② 线程执行sleep()方法后转入阻塞（blocked）状态，而执行yield()方法后转入就绪（ready）状态；
③ sleep()方法需要声明抛出InterruptedException，而yield()方法没有声明任何异常；
④ sleep()方法比yield()方法（跟操作系统CPU调度相关）具有更好的可移植性。

 同步代码块和同步方法的区别

　　两者的区别主要体现在同步锁上面。对于实例的同步方法，因为只能使用this来作为同步锁，如果一个类中需要使用到多个锁，为了避免锁的冲突，必然需要使用不同的对象，这时候同步方法不能满足需求，只能使用同步代码块(同步代码块可以传入任意对象)；或者多个类中需要使用到同一个锁，这时候多个类的实例this显然是不同的，也只能使用同步代码块，传入同一个对象。

##### 2.12 对比synchronized和Lock

1)、synchronized是关键字，就和if...else...一样，是语法层面的实现，因此synchronized获取锁以及释放锁都是Java虚拟机帮助用户完成的；ReentrantLock是类层面的实现，因此锁的获取以及锁的释放都需要用户自己去操作。特别再次提醒，ReentrantLock在lock()完了，一定要手动unlock()，一般放在finally语句块中。

2)、synchronized简单，简单意味着不灵活，而ReentrantLock的锁机制给用户的使用提供了极大的灵活性。这点在Hashtable和ConcurrentHashMap中体现得淋漓尽致。synchronized一锁就锁整个Hash表，而ConcurrentHashMap则利用ReentrantLock实现了锁分离，锁的只是segment而不是整个Hash表

3)、synchronized是不公平锁，而ReentrantLock可以指定锁是公平的还是非公平的

4)、synchronized实现等待/通知机制通知的线程是随机的，ReentrantLock实现等待/通知机制可以有选择性地通知

5)、和synchronized相比，ReentrantLock提供给用户多种方法用于锁信息的获取，比如可以知道lock是否被当前线程获取、lock被同一个线程调用了几次、lock是否被任意线程获取等等

总结起来，我认为如果只需要锁定简单的方法、简单的代码块，那么考虑使用synchronized，复杂的多线程处理场景下可以考虑使用ReentrantLock。

##### 2.13 Volatile关键字：

volatile关键字是Java并发的最轻量级实现，本质上有两个功能，在生成的汇编语句中加入LOCK关键字和内存屏障

作用就是保证每一次线程load和write两个操作，都会直接从主内存中进行读取和覆盖，而非普通变量从线程内的工作空间（默认各位已经熟悉Java多线程内存模型）

但它有一个很致命的缺点，导致它的使用范围不多，就是他只保证在读取和写入这两个过程是线程安全的。如果我们对一个volatile修饰的变量进行多线程 下的自增操作，还是会出现线程安全问题。根本原因在于volatile关键字无法对自增进行安全性修饰，因为自增分为三步，读取-》+1-》写入。中间多 个线程同时执行+1操作，还是会出现线程安全性问题。

##### 2.14 Yeild功能

主要作用是：让线程放弃当前的CPU资源，让其他的任务去占用CPU的执行时间。但是执行放弃的时间不定，一般用于debug。

##### 2.15 Thread类的3个关键方法（sleep、join、yield）
Thread类有三个关键方法：` sleep`、` join` 、`yeild `
- sleep：让当前线程暂停指定的时间（ms），wait方法依赖于同步，而sleep方法可以直接调用。而更深层次的区别在于sleep方法只是暂时让出CPU的执行权，并不释放锁。而wait方法则需要释放锁。

  ```java
  public class SleepTest {

      public synchronized void sleepMethod() {
          System.out.println("Sleep Start...");
          try {
              Thread.sleep(1000);
          } catch (InterruptedException e) {
              e.printStackTrace();
          }
          System.out.println("Sleep End...");
      }
      public synchronized void waitMethod() {
          System.out.println("Wait Start...");
          try {
              wait(1000);
          } catch (InterruptedException e) {
              e.printStackTrace();
          }
          System.out.println("Wait End...");
      }

      public static void main(String[] args) {

          SleepTest sleepTest = new SleepTest();

          for (int i = 0; i < 3; i++) {
              new Thread(() -> sleepTest.sleepMethod()).start();
          }

          try {
              Thread.sleep(10000);
              System.out.println("---------------");
          } catch (InterruptedException e) {
              e.printStackTrace();
          }

          SleepTest waitTest = new SleepTest();

          for (int i = 0; i < 3; i++) {
              new Thread(() -> waitTest.waitMethod()).start();
          }
      }
  }
  ```

  运行结果：

  ```
  Sleep Start...
  Sleep End...
  Sleep Start...
  Sleep End...
  Sleep Start...
  Sleep End...
  ---------------
  Wait Start...
  Wait Start...
  Wait Start...
  Wait End...
  Wait End...
  Wait End...
  ```

  这个结果的区别很明显，通过sleep方法实现的暂停，程序是顺序进入同步块的，只有当上一个线程执行完成的时候，下一个线程才能进入同步方法，sleep暂停期间一直持有monitor对象锁，其他线程是不能进入的。而wait方法则不同，当调用wait方法后，当前线程会释放持有的monitor对象锁，因此，其他线程还可以进入到同步方法，线程被唤醒后，需要竞争锁，获取到锁之后再继续执行。

- yield：yield方法的作用是暂停当前线程，以便其他线程有机会执行，不过不能指定暂停的时间，并且也不能保证当前线程马上停止。yield方法只是将Running状态转变为Runnable状态。

```
public class YieldTest implements Runnable{
      @Override
      public void run() {
          try {
              Thread.sleep(1000);
          } catch (InterruptedException e) {
              e.printStackTrace();
          }
          for (int i = 0; i < 5; i++) {
              System.out.println(Thread.currentThread().getName() + ": " + i);
              Thread.yield();
          }
      }
      public static void main(String[] args) {
          YieldTest runn = new YieldTest();
          new Thread(runn, "No.1 Thread").start();
          new Thread(runn, "No.2 Thread").start();
      }
  }
```

  运行结果：

  ```java
  No.1 Thread: 0
  No.2 Thread: 0
  No.2 Thread: 1
  No.1 Thread: 1
  No.2 Thread: 2
  No.1 Thread: 2
  No.2 Thread: 3
  No.1 Thread: 3
  No.1 Thread: 4
  No.2 Thread: 4
  ```

  这个例子就是通过yield方法来实现两个线程的交替执行。不过请注意：这种交替并不一定能得到保证

- join：底层是用wait来实现的

#####  2.16 项目中你用到这个Volatile关键字吗，用于哪个场景

- 状态标志

- 一次性安全发布（防止调用未加载/初始化的对象）

```
 public class Main {
      public static void main(String[] args) {
          ComplexObject obj = new ComplexObject();
          // 线程1
          new Thread(()->{
              do{
                  if(obj.field != null){
                      break;
                  }
              }while (true);
              System.out.println("exit when obj.field is not null ");
          }).start();
          // 线程2
          new Thread(()->{
              try {
                  Thread.sleep(1000);
                  System.out.println("init obj");
                  obj.init();
              } catch (InterruptedException e) {
                  e.printStackTrace();
              }
          }).start();
      }

      static class ComplexObject{
          public volatile ComplexObject field = null;

          public void init(){
              field = new ComplexObject();
          }

      }
  }

  // 线程1会不停的检测复合对象的field属性是否为空，只有当不为空的时候才会结束循环；
  // 而线程2会在启动1秒后才给obj进行初始化；
  // 也就是说，obj对象真正出于发布可用的状态是在线程2中初始化之后，因此这里需要对field属性使用volatile，否则线程2对obj的初始化将对线程1永远不可见，线程1也就不会结束了。
```
- volatile bean：当某个线程对 Java Bean 的属性进行修改时，要保证其他线程都能探测到这个修改，因此这里的属性需要使用`volatile`来修饰。

  ​


##### 2.17 Volatitle关键字声明之后，编译器不会优化的原理

为了解决线程并发问题，Java引入了同步块synchronized关键字与轻量级同步操作volatile关键字。

- **synchronized** ：所有加上synchronized 的块语句和方法，在多线程访问的时候，同一时刻只能有一个线程能够执行这个方法或这段代码。
使用实例：

```
  public class SynchronizedTest implements Runnable{

      private static int count;

      SynchronizedTest() {
          count = 0;
      }
      @Override
      public synchronized void run() {
  //    public void run() {
          for (int i = 0; i < 4; i++) {
              System.out.println(Thread.currentThread().getName() + ": " + count++);
              try {
                  Thread.sleep(1000);
              } catch (InterruptedException e) {
                  e.printStackTrace();
              }
          }
      }

      public static void main(String[] args) {
          SynchronizedTest synchronizedTest = new SynchronizedTest();
          new Thread(synchronizedTest, "No.1 Thread").start();
          new Thread(synchronizedTest, "No.2 Thread").start();
      }
  }
```

  运行结果：

```java
  // 不使用 synchronized，每次打印结果不一致
  No.1 Thread: 0
  No.2 Thread: 1
  No.2 Thread: 3
  No.1 Thread: 2
  No.1 Thread: 4
  No.2 Thread: 5
  No.2 Thread: 7
  No.1 Thread: 6
      
  // 使用 synchronized，每次打印结果一致
  No.1 Thread: 0
  No.1 Thread: 1
  No.1 Thread: 2
  No.1 Thread: 3
  No.2 Thread: 4
  No.2 Thread: 5
  No.2 Thread: 6
  No.2 Thread: 7
```
- **volatile** ：可以被看作是一种 “程度较轻的 `synchronized`”；与 `synchronized` 块相比，volatile 变量所需的编码较少，并且运行时开销也较少，但是它所能实现的功能也仅是 `synchronized` 的一部分。

  当对非 volatile 的一般变量进行读写时，每个线程先从内存拷贝变量到CPU缓存中，处理后再更新内存中变量的值。然而，如果计算机有多个CPU，每个线程可能在不同的CPU上被处理，这意味着每个线程可以拷贝变量到不同的CPU cache中。 

  这会带来一个问题，比如说 `i += 1;` 指令，`i` 是一个非 volatile 的静态变量，初始值为0，有两个线程执行了该条指令，按照预期结果，`i` 值将变为 2 。然而线程1将值为0的变量 `i` 拷贝至CPU Cache处理后，还未将值更新回内存，线程2就将值为0的 `i` 拷贝至另外的CPU Cache进行处理。最后得到的结果是令人诧异的 **1** 。

  举个例子：

```java
  public class VolatileTest {
      private static int count = 0;

      public static void main(String[] args) {
          for (int i = 0; i < 10000; i++) {
              new Thread(() -> count++).start();
          }
          System.out.println(count); // 结果可能为 9851, 5709, ... 总之每次都不一样！
      }
  }
```

  这段程序将用多个线程将变量 `count` 值 + 1 了 10000 次，然而输出结果每次都不固定，并且大概率不是 10000。

  这个时候就需要 volatile 登场了。volatile 变量不会被缓存在处理器不可见的地方（CPU Cache、线程私有区），保证了每次读写变量都是从内存中读，跳过了CPU cache这一步。所以当一个线程修改了这个变量的值，新值对于其他线程来说是立即更新、可知的。 

  不过， volatile 关键字能保证的仅仅是修改可见性，而非有序性，将上述代码修改为：

```java
  public class VolatileTest {
      private static volatile int count = 0;

      public static void main(String[] args) {
          for (int i = 0; i < 10000; i++) {
              new Thread(() -> count++).start();
          }
          System.out.println(count); // 结果可能为 9851, 5709, ... 总之每次仍然不一样！
      }
  }
```

  因为负责打印的main线程与count+1的线程执行顺序是混乱的，所以会导致上述结果。

  修改代码如下：

```java
  public class VolatileTest {
      private static volatile int count = 0;

      public static void main(String[] args) {
          for (int i = 0; i < 10000; i++) {
              new Thread(() -> count++).start();
          }
          try {
              Thread.sleep(1000);  // 等待自增线程执行完毕
          } catch (InterruptedException e) {
              e.printStackTrace();
          }
          System.out.println(count); // 打印结果为10000
      }
  }

  // 或是使用atomic包

  public class VolatileTest {
      private static AtomicInteger count = new AtomicInteger(0);

      public static void main(String[] args) {
          for (int i = 0; i < 10000; i++) {
              new Thread(() -> count.incrementAndGet()).start();
          }
          try {
              Thread.sleep(1000);
          } catch (InterruptedException e) {
              e.printStackTrace();
          }
          System.out.println(count.get());
      }
  }
```
  关于 volatile 关键字的适用场景可参考：[正确使用 Volatile 变量](https://www.ibm.com/developerworks/cn/java/j-jtp06197.html)

  我们只能在有限的一些情形下使用 volatile 变量替代锁。要使 volatile 变量提供理想的线程安全，必须同时满足下面两个条件：

  - 对变量的写操作不依赖于当前值。（比如说`i = 10 ` 不依赖当前 `i` 值，而 `i++` 依赖）
  - 该变量没有包含在具有其他变量的不变式中。（比如说不能将该变量用于边界检查，因为修改不保证有序，很有可能这个变量会同时满足 `i < 3 ` 和 `i > 4` ，薛定谔的变量值。。）

  除了保证变量的内存可见性外，volatile 关键字的一大功能是禁止指令重排，即关闭JVM中必要的代码优化，其实现原理是提供内存屏障的方式来防止指令被重排：

  1. 每个volatile写操作的前面插入一个StoreStore屏障；
  2. 在每个volatile写操作的后面插入一个StoreLoad屏障；
  3. 在每个volatile读操作的后面插入一个LoadLoad屏障；
  4. 在每个volatile读操作的后面插入一个LoadStore屏障。
 
##### 2.18 线程本地变量Threadlocal
ThreadLocal是线程内部的数据存储类，通过它可以指定的线程中存储数据，数据存储以后，只有在指定线程中可以获取到存储的数据，对于其他线程来说则无法获取数据. 
用ThreadLocalMap实现的；

##### 2.19 线程池的作用：
线程池作用就是限制系统中执行线程的数量。
     根据系统的环境情况，可以自动或手动设置线程数量，达到运行的最佳效果；少了浪费了系统资源，多了造成系统拥挤效率不高。用线程池控制线程数量，其他线程排队等候。一个任务执行完毕，再从队列的中取最前面的任务开始执行。若队列中没有等待进程，线程池的这一资源处于等待。当一个新任务需要运行时，如果线程池中有等待的工作线程，就可以开始运行了；否则进入等待队列。
**为什么要用线程池:**
1.减少了创建和销毁线程的次数，每个工作线程都可以被重复利用，可执行多个任务。
2.可以根据系统的承受能力，调整线程池中工作线线程的数目，防止因为消耗过多的内存，而把服务器累趴下(每个线程需要大约1MB内存，线程开的越多，消耗的内存也就越大，最后死机)。
 
### 3.计算机网络
##### 3.1 介绍ARP协议是干什么的
通过[网络地址](https://zh.wikipedia.org/wiki/%E7%B6%B2%E8%B7%AF%E4%BD%8D%E5%9D%80)(例：[IPv4](https://zh.wikipedia.org/wiki/IPv4))来定位[MAC地址](https://zh.wikipedia.org/wiki/MAC%E5%9C%B0%E5%9D%80) (也称为以太地址)，网络层定位链路层
##### 3.2 Http请求底层是用的什么协议

TCP

##### 3.3 Tcp连接过程

![](http://img.blog.csdn.net/20140608195019968?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvbnNfY29kZQ==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)

![](http://img.blog.csdn.net/20140608204149078?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvbnNfY29kZQ==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)

##### 3.4 连接时队列大小是什么原理

- server端的半连接队列(syn队列)，内核决定，net.ipv4.tcp_max_syn_backlog
- server端的完全连接队列(accpet队列)，min(net.core.somaxconn，backlog)，内核参数和自定义的最小值
##### 3.5 DNS协议作用，底层用的什么协议
可以将域名转换为[IP地址](https://zh.wikipedia.org/wiki/IP%E5%9C%B0%E5%9D%80)，UDP

#####  3.6TCP如何保证可靠传输？三次握手过程？
**可靠传输：**
- 确认、重传机制（滑动窗口实现）
-  数据校验
-  数据合理分片与排序
-  拥塞控制（慢开始和拥塞避免、快恢复和快重传）
-  流量控制（滑动窗口）

**三次握手的过程：**
- 客户端发送syn报文（client: SYN_SENT)
-  服务端接收syn报文，发送syn+ack报文（server: SYN_RECV）
-  客户端接收syn+ack报文，发送ack报文（client: Established）
-  服务端接收到syn报文，连接建立（server: Established）

##### 3.7 TCP和UDP区别？

- TCP 面向连接，UDP 面向无连接
-  TCP 传输可靠，UDP 不可靠
-  TCP 大量数据（数据流），UDP 少量数据（数据包）
-  TCP 较慢，UDP 较快
##### 3.8 http1.0和1.1有什么区别

- 长连接：HTTP 1.0需要使用keep-alive参数来告知服务器端要建立一个长连接，而HTTP1.1默认支持长连接。
- 带宽优化：
  - HTTP/1.1加入了一个新的状态码100（Continue），客户端事先发送一个只带头域的请求，拒绝发送401; 接受则发送100,客户端就可以继续发送带实体的完整请求了
  - 断点续传（支持传送内容的一部分。这样当客户端已经有一部分的资源后，只需要跟服务器请求另外的部分资源即可）
- HOST域：web server上的多个虚拟站点可以共享同一个ip和端口。
- 缓存处理：HTTP1.1引入了更多的缓存控制策略
- 新增了24个错误状态响应码：如409（Conflict）表示请求的资源与资源的当前状态发生冲突；410（Gone）表示服务器上的某个资源被永久性的删除

##### 3.9 HTTP1.1 HTTP 2.0主要区别
- 多路复用（NIO）：做到同一个连接并发处理多个请求，不需要额外建立TCP
- 数据压缩：HTTP1.1不支持header数据的压缩，HTTP2.0使用HPACK算法对header的数据进行压缩，这样数据体积小了，在网络上传输就会更快。
- 服务器推送：请求数据的时候，服务器会顺便把一些客户端需要的资源一起推送到客户端

##### 3.10 TCP粘包、拆包（半包、断包）

- 粘包：多个混一起
- 拆包：一个分多个

造成原因：

1. 要发送的数据**大于TCP发送缓冲区剩余空间大小**，发生拆包；
2. 待发送数据大于MSS（最大报文长度），TCP在传输前进行拆包；
3. 要发送的数据**小于TCP发送缓冲区的大小**，TCP将多次写入缓冲区的数据一次发送出去，造成粘包;
4. 接收方没能及时地接收缓冲区的数据，造成粘包;

过大拆包，过小粘包。

如何处理：

1. **使用带消息头的协议（客户端）**、消息头存储消息开始标识及消息长度信息，服务端获取消息头的时候解析出消息长度，然后向后读取该长度的内容。
2. **设置定长消息（服务端-客户端共同实现）**，服务端每次读取既定长度的内容作为一条完整消息。
3. **设置消息边界（客户端）**，服务端从网络流中按消息编辑分离出消息内容。

##### 3.11 Tcp的time_wait

客户端主动关闭连接时，会发送最后一个ack后，然后会进入TIME_WAIT状态，再停留2个MSL时间(后有MSL的解释)，进入CLOSED状态。

TCP/IP协议就是这样设计的，是不可避免的。主要有两个原因:

1. 可靠地实现TCP全双工连接的终止，防止最后一个 ACK 丢失后无法再次响应服务端重传的 FIN；

四次握手过程中，最终的ACK是由主动关闭连接的一端发出的，如果这个ACK丢失，对方将重发出最终的 FIN，因此A端必须维护状态信息（TIME_WAIT）允许它重发最终的ACK。如果A端不维持TIME_WAIT状态，而是处于CLOSED 状态，那么A端将响应RST错误（关闭连接异常）

2. 保证当成功建立一个新TCP连接的时候，来自旧连接重复分组已经在网络中消逝。
**MSL**：指的是报文段的最大生存时间，如果报文段在网络活动了MSL时间，还没有被接收，那么会被丢弃。关于MSL的大小，RFC 793协议中给出的建议是两分钟，不过实际上不同的操作系统可能有不同的设置，以**Linux为例，通常是半分钟，两倍的MSL就是一分钟，也就是60秒**，并且这个数值是硬编码在内核中的，也就是说除非你重新编译内核，否则没法修改它。

##### 3.12 HTTPS 握手过程

1、**ClientHello** ：客户端首先会**将自己支持的加密算法**，打个包告诉服务器端。
2、**ServerHello** ：服务器端从客户端发来的加密算法中，选出一组加密算法和HASH算法（注，HASH也属于加密），并将自己的**身份信息以证书的形式发回给客户端**。而证书中包含了网站的地址，加密用的公钥，以及证书的颁发机构等；
  这里有提到公钥的概念是故事中没有的。我们常见的加密算法一般是一些对称的算法，如凯撒加密；对称算法即加密用的密钥和解密用的密钥是一个。如故事中的密钥是4。还有一种加密解密算法称之为非对称算法。这种算法加密用的密钥（公钥）和解密用的密钥（私钥）是两个不同的密钥；通过公钥加密的内容一定要使用私钥才能够解密。
  这里，服务器就将自己用来加密用的公钥一同发还给客户端，而私钥则服务器保存着，用户解密客户端加密过后的内容。

3、**Verification** ：客户端收到了服务器发来的数据包后，会做这么几件事情：
 1）验证一下证书是否合法。一般来说，证书是用来标示一个站点是否合法的标志。如果说该证书由权威的第三方颁发和签名的，则说明证书合法。
 2）如果证书合法，或者客户端接受和信任了不合法的证书，则**客户端就会随机产生一串序列号，使用服务器发来的公钥进行加密。**这时候，一条返回的消息就基本就绪。
 3）最后**使用服务器挑选的HASH算法，将刚才的消息使用刚才的随机数进行加密，生成相应的消息校验值，与刚才的消息一同发还给服务器。**

4、服务器接受到客户端发来的消息后，会做这么几件事情：
 1）使用私钥解密上面第2）中公钥加密的消息，得到客户端产生的随机序列号。
 2）**使用该随机序列号，对该消息进行加密，验证的到的校验值是否与客户端发来的一致**。如果一致则说明消息未被篡改，可以信任。
 3）最后，使用该随机序列号，加上之前第2步中选择的加密算法，**加密一段握手消息，发还给客户端。同时HASH值也带上。**

5、客户端收到服务器端的消息后，接着做这么几件事情：
 1）**计算HASH值是否与发回的消息一致**
 2）检查消息是否为握手消息

6、握手结束后，客户端和服务器端使用握手阶段产生的随机数以及**挑选出来的算法进行对称加解密的传输。**

简而言之：

1. 客户端发送支持的加密算法
2. 服务端返回选择的加密算法、证书（包含公钥）
3. 客户端验证证书，如不合法则警告用户
4. 若证书合法，客户端将生成一个随机数作为密钥，使用公钥将此密钥加密，并发给服务端
5. 服务端收到信息后，使用私钥解密出加密算法的密钥
6. 双方开始使用选择的加密算法与随机数来进行加解密传输

省略了hash算法生成随机数摘要的部分

总结一下就是：

（1） 客户端向服务器端索要并验证公钥。
（2） 双方协商生成"对话密钥"。
（3） 双方采用"对话密钥"进行加密通信。

前两步是握手过程。

### 6 数据库基础
##### 6.1 数据库主键和外键有什么区别

- 定义：

主键：唯一标识一条记录，不能有重复，不允许为空。
外键：表的外键是另一表的主键，外键是可以有重复的，可以是空值。
索引：该字段没有重复值，但可以有一个空值。

- 作用：

主键：用来保证数据完整性
外键：用来和其他表建立联系用
索引：用来提高查询排序的速度

- 个数：

主键：主键只能有一个。
外键：一个表可以有多个外键。
索引：一个表可以有多个唯一索引。

##### 6.2 数据库视图和表有什么区别

表：具体的，实际物理记录

视图：抽象的，依附表而存在，删除不影响实际物理表。



##### 6.3 数据事务你能简单介绍一下吗，ACID

一个数据库事务通常包含了一个序列的对数据库的读/写操作。它的存在包含有以下两个目的：

1. 为数据库操作序列提供了一个从失败中恢复到正常状态的方法，同时提供了数据库即使在异常状态下仍能保持一致性的方法。
2. 当多个[应用程序](https://zh.wikipedia.org/wiki/%E5%BA%94%E7%94%A8%E7%A8%8B%E5%BA%8F)在[并发](https://zh.wikipedia.org/wiki/%E5%B9%B6%E5%8F%91)访问数据库时，可以在这些应用程序之间提供一个隔离方法，以防止彼此的操作互相干扰。

 数据库事务必须具备ACID特性，ACID是Atomic（原子性）、Consistency（一致性）、Isolation（隔离性）和Durability（持久性）的英文缩写。

　 原子性：指整个数据库事务是不可分割的工作单位。只有使数据库中所有的操作执行成功，才算整个事务成功；事务中任何一个SQL语句执行失败，那么已经执行成功的SQL语句也必须撤销，数据库状态应该退回到执行事务前的状态。

　 一致性：指数据库事务不能破坏关系数据的完整性以及业务逻辑上的一致性。例如对银行转帐事务，不管事务成功还是失败，应该保证事务结束后ACCOUNTS表中Tom和Jack的存款总额为2000元。

　 隔离性：指的是在并发环境中，当不同的事务同时操纵相同的数据时，每个事务都有各自的完整数据空间。由并发事务所做的修改必须与任何其他并发事务所做的修改隔离。事务查看数据更新时，数据所处的状态要么是另一事务修改它之前的状态，要么是另一事务修改它之后的状态，**事务不会查看到中间状态的数据**。

　 持久性：指的是只要事务成功结束，它对数据库所做的更新就必须永久保存下来。即使发生系统崩溃，重新启动数据库系统后，数据库还能恢复到事务成功结束时的状态。

　　事务的（ACID）特性是由关系数据库管理系统（RDBMS，数据库系统）来实现的。数据库管理系统采**用日志来保证事务的原子性、一致性和持久性**。日志记录了事务对数据库所做的更新，如果某个事务在执行过程中发生错误，就可以根据日志，撤销事务对数据库已做的更新，使数据库退回到执行事务前的初始状态。

　　数据库管理系统**采用锁机制来实现事务的隔离性**。当多个事务同时更新数据库中相同的数据时，只允许持有锁的事务能更新该数据，其他事务必须等待，直到前一个事务释放了锁，其他事务才有机会更新该数据。



##### 6.4 事务特性分别什么特征，什么原理

ACID



##### 6.5  Mysql数据库隔离级别一般用哪个

**Read Uncommitted（读取未提交内容）**

在该隔离级别，所有事务都可以看到其他未提交事务的执行结果。本隔离级别很少用于实际应用，因为它的性能也不比其他级别好多少。读取未提交的数据，也被称之为脏读（Dirty Read）。

**Read Committed（读取提交内容）**

这是大多数数据库系统的默认隔离级别（sqlserver、但不是MySQL默认的）。它满足了隔离的简单定义：一个事务只能看见已经提交事务所做的改变。这种隔离级别 也支持所谓的不可重复读（Nonrepeatable Read），因为同一事务的其他实例在该实例处理其间可能会有新的commit，所以同一select可能返回不同结果。

**Repeatable Read（可重读）**

**这是MySQL的默认事务隔离级别**，它确保同一事务的多个实例在并发读取数据时，会看到同样的数据行。不过理论上，这会导致另一个棘手的问题：幻读 （Phantom Read）。简单的说，幻读指当用户读取某一范围的数据行时，另一个事务又在该范围内插入了新行，当用户再读取该范围的数据行时，会发现有新的“幻影” 行。InnoDB和Falcon存储引擎通过多版本并发控制（MVCC，Multiversion Concurrency Control）机制解决了该问题。

**Serializable（可串行化）**

这是最高的隔离级别，它通过强制事务排序，使之不可能相互冲突，从而解决幻读问题。简言之，它是在每个读的数据行上加上共享锁。在这个级别，可能导致大量的超时现象和锁竞争。

这四种隔离级别采取不同的锁类型来实现，若读取的是同一个数据的话，就容易发生问题。例如：

**脏读**(Drity Read)：某个事务已更新一份数据，另一个事务在此时读取了同一份数据，由于某些原因，前一个RollBack了操作，则后一个事务所读取的数据就会是不正确的。

**不可重复读**(Non-repeatable read):在一个事务的两次查询之中数据不一致，这可能是两次查询过程中间插入了一个事务更新的原有的数据。

**幻读**(Phantom Read):在一个事务的两次查询中数据笔数不一致，例如有一个事务查询了几列(Row)数据，而另一个事务却在此时插入了新的几列数据，先前的事务在接下来的查询中，就会发现有几列数据是它先前所没有的。



##### 6.6 Hibernate隔离级别一般用的哪个

2和4比较多，可重读

#####  6.7 数据库大概怎么实现的索引，底层用了什么数据结构，大概介绍一下

B树及其变种B+树

B树中每个节点包含了键值和键值对于的数据对象存放地址指针，所以成功搜索一个对象可以不用到达树的叶节点。

B+树非叶节点中存放的关键码并不指示数据对象的地址指针，非也节点只是索引部分。所有的叶节点在同一层上，包含了全部关键码和相应数据对象的存放地址指针，且叶节点按关键码从小到大顺序链接。

##### 6.8 数据库范式
**范式（NF）的定义：**范式是符合某一种级别的关系模式的集合，表示一个关系内部的各属性之间的联系的合理化程度；实际上你可以理解为**一张数据表的表结构所符合的某种设计标准的级别，**就像家里装修买钢材，最环保的是E0级，其次是E1级，还有E2级等等；数据库范式也分为1NF，2NF，3NF，BCNF，4NF，5NF。一般我们设计数据库的时候最多只考虑到BCNF就够；符合高一级别的范式的设计必定符合低一级别的范式，例如符合2NF的关系模式必定符合1NF；

**关系模式和关系**：关系模式和关系的区别，类似于面向对象程序设计中“类”和“对象”的区别。关系是关系模式的一个实例，你可以把“关系”理解为一张带数据的表，而关系模式是这张表的表结构；

**码**：关系中的某个属性或者几个属性的组合，用于区分每个元组（可以把元组理解为一张表中的每条记录，也就是每一行）
**第一范式（1NF）**：符合1NF的关系中的每个属性都不可再分；
**第二范式（2NF）**：2NF在1NF的基础之上，消除了**非主属性对于码的部分函数依赖；**下面对“函数依赖”，“码”，“非主属性”，“部分函数依赖”进行一下解释；
- 函数依赖：若在一张表中，在属性（或属性组）X的值确定的情况下，必能能确定属性Y的值，那么就可以说Y函数依赖于X，写作X->Y。也就是说，在数据表中，不存在任意两条记录，它们在X属性（或属性组）上的值相同，而在Y属性上的值不同。这也就是“函数依赖”名字的由来，类似于函数关系 y = f(x)，在x的值确定的情况下，y的值一定是确定的。
- 完全函数依赖：在一张表中，若 X → Y，且对于 X 的任何一个真子集（假如属性组 X 包含超过一个属性的话），X ' → Y 不成立，那么我们称 Y 对于 X 完全函数依赖，记作 X F→ Y。（那个F应该写在箭头的正上方，没办法打出来……，正确的写法如图）
![](https://pic1.zhimg.com/80/12513de20079d12b99d946072df7311a_hd.jpg)
- 部分函数依赖：假如 Y 函数依赖于 X，但同时 Y 并不完全函数依赖于 X，那么我们就称 Y 部分函数依赖于 X，记作 X  P→ Y，如图2。
- 传递函数依赖：假如 Z 函数依赖于 Y，且 Y 函数依赖于 X （『Y 不包含于 X，且 X 不函数依赖于 Y』这个前提），那么我们就称 Z 传递函数依赖于 X ；
- 码：设 K 为某表中的一个属性或属性组，若除 K 之外的所有属性都完全函数依赖于 K（这个“完全”不要漏了），那么我们称 K 为候选码，简称为码。在实际中我们通常可以理解为：假如当 K 确定的情况下，该表除 K 之外的所有属性的值也就随之确定，那么 K 就是码。一张表中可以有超过一个码。（实际应用中为了方便，通常选择其中的一个码作为主码）
- 非主属性：包含在任何一个码中的属性成为主属性。
**第三范式（3NF）**：3NF在2NF的基础之上，消除了非主属性对于码的传递函数依赖。也就是说， 如果存在非主属性对于码的传递函数依赖，则不符合3NF的要求。
**BC范式（BCNF）**：在 3NF 的基础上消除主属性对于码的部分与传递函数依赖

##### 6.9 关系型数据库和非关系型数据库的区别

数据库类型 | 特性 | 优点 | 缺点
- | :-: | -: 
关系型数据库SQLite、Mysql、Oracle | 1.关系型数据库是指采用了关系模型来组织数据的数据库，2.关系型数据库最大的特点就是事务的一致性；3.简单来讲，关系模型指的就是二维表格模型，而一个关系型数据库就是由二维表及其之间的联系所组成的一个数据组织；| 1、容易理解：二维表结构是非常贴近逻辑世界一个概念，关系模型相对网状、层次等其他模型来说更容易理解；2、使用方便：通用的SQL语言使得操作关系型数据库非常方便；3、易于维护：丰富的完整性(实体完整性、参照完整性和用户定义的完整性)大大减低了数据冗余和数据不一致的概率；4、支持SQL，可用于在一个表和多个表之间做复杂的查询。| 1为了维护一致性所付出的巨大代价就是其读写性能比较差；2固定的表结构；3高并发读写需求；4、海量数据的高效率读写；
非关系型数据库Mongodb、redis、Hbase | 1、使用键值对存储数据；2、分布式；3、一般不支持ACID特性；4、非关系型数据库严格上不是一种数据库，应该是一种数据结构化存储方法的集合。| 1、无需经过sql层的解析，读写性能很高；2、基于键值对，数据没有耦合性，容易扩展；3、存储数据的格式：nosql的存储格式是key,value形式、文档形式、图片形式等等，而关系型数据库则只支持基础类型。| 1、不提供sql支持，学习和使用成本较高；2、无事务处理，附加功能bi和报表等支持也不好；

> 注1：数据库事务必须具有ACID属性，ACID是Atomic原子性，Consistency一致性，Isolation隔离性，Durability持久性；
> 注2：数据的持久存储，尤其是海量数据的持久存储，还是需要一种关系型数据库；
